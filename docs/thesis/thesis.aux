\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Chapter 1: Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Weekly testing rate for each state across the United States, where we define testing rate as the total number of tests in that week for a given state over the state's population size. Each line corresponds to a single state. Highlighted in color are the states at the extremes, where Rhode Island has the highest median testing rate and Mississippi has the lowest. Seeing the extent to which testing rate varies over time and by state underscores the importance of thinking about incomplete testing when estimating the true number of infections.\relax }}{2}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:test-rate-all-states}{{1.1}{2}{Weekly testing rate for each state across the United States, where we define testing rate as the total number of tests in that week for a given state over the state's population size. Each line corresponds to a single state. Highlighted in color are the states at the extremes, where Rhode Island has the highest median testing rate and Mississippi has the lowest. Seeing the extent to which testing rate varies over time and by state underscores the importance of thinking about incomplete testing when estimating the true number of infections.\relax }{figure.caption.4}{}}
\newlabel{fig:unnamed-chunk-6}{{1.1}{2}{Weekly testing rate for each state across the United States, where we define testing rate as the total number of tests in that week for a given state over the state's population size. Each line corresponds to a single state. Highlighted in color are the states at the extremes, where Rhode Island has the highest median testing rate and Mississippi has the lowest. Seeing the extent to which testing rate varies over time and by state underscores the importance of thinking about incomplete testing when estimating the true number of infections.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 2: Overview of Approach}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{overview}{{2}{5}{Overview of Approach}{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Figure from Wu et al. (2020) showing the ratio of total estimated infections as of April 18, 2020 to the number of cases confirmed by a positive PCR test. Total estimated infections were obtained by a correction for incomplete testing and imperfect diagnostic test accuracy.\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:originalfigwu}{{2.1}{5}{Figure from Wu et al. (2020) showing the ratio of total estimated infections as of April 18, 2020 to the number of cases confirmed by a positive PCR test. Total estimated infections were obtained by a correction for incomplete testing and imperfect diagnostic test accuracy.\relax }{figure.caption.5}{}}
\newlabel{fig:unnamed-chunk-7}{{2.1}{5}{Figure from Wu et al. (2020) showing the ratio of total estimated infections as of April 18, 2020 to the number of cases confirmed by a positive PCR test. Total estimated infections were obtained by a correction for incomplete testing and imperfect diagnostic test accuracy.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Full implementation of probabilistic bias analysis, first correcting for incomplete testing, and then correcting for imperfect test accuracy.\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:diagram}{{2.2}{9}{Full implementation of probabilistic bias analysis, first correcting for incomplete testing, and then correcting for imperfect test accuracy.\relax }{figure.caption.6}{}}
\newlabel{fig:unnamed-chunk-8}{{2.2}{9}{Full implementation of probabilistic bias analysis, first correcting for incomplete testing, and then correcting for imperfect test accuracy.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Outline of Following Sections}{10}{section.2.1}\protected@file@percent }
\newlabel{outline-of-following-sections}{{2.1}{10}{Outline of Following Sections}{section.2.1}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 3: Background}{11}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{background}{{3}{11}{Background}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Probabalistic Bias Analysis}{11}{section.3.1}\protected@file@percent }
\newlabel{probabalistic-bias-analysis}{{3.1}{11}{Probabalistic Bias Analysis}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Bayesian Melding}{12}{section.3.2}\protected@file@percent }
\newlabel{bayesian-melding}{{3.2}{12}{Bayesian Melding}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Simple Discrete Example}{14}{subsection.3.2.1}\protected@file@percent }
\newlabel{simple-discrete-example}{{3.2.1}{14}{Simple Discrete Example}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A simple discrete example where $M$ is not invertible, since $M(2)=M(3)=2$.\relax }}{14}{figure.caption.8}\protected@file@percent }
\newlabel{fig:dex}{{3.1}{14}{A simple discrete example where $M$ is not invertible, since $M(2)=M(3)=2$.\relax }{figure.caption.8}{}}
\newlabel{fig:unnamed-chunk-11}{{3.1}{14}{A simple discrete example where $M$ is not invertible, since $M(2)=M(3)=2$.\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Specifing the Distributions of $f_\theta (\theta )$ and $f_\phi ^{direct}(\phi )$\relax }}{14}{table.caption.9}\protected@file@percent }
\newlabel{tab:unnamed-chunk-12}{{3.1}{14}{Specifing the Distributions of $f_\theta (\theta )$ and $f_\phi ^{direct}(\phi )$\relax }{table.caption.9}{}}
\newlabel{table:example-dist}{{3.1}{14}{Specifing the Distributions of $f_\theta (\theta )$ and $f_\phi ^{direct}(\phi )$\relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces  Comparing the direct, induced, and pooled distributions on $\phi $. Each is a discrete distribution where $\phi $ can take on only values 1 or 2. Note that the probability mass of a given value of $\phi $ for the pooled distribution falls in between the probability masses of the induced and direct distributions for that value of $\phi $.\relax }}{16}{figure.caption.12}\protected@file@percent }
\newlabel{fig:comp}{{3.2}{16}{Comparing the direct, induced, and pooled distributions on $\phi $. Each is a discrete distribution where $\phi $ can take on only values 1 or 2. Note that the probability mass of a given value of $\phi $ for the pooled distribution falls in between the probability masses of the induced and direct distributions for that value of $\phi $.\relax }{figure.caption.12}{}}
\newlabel{fig:unnamed-chunk-14}{{3.2}{16}{Comparing the direct, induced, and pooled distributions on $\phi $. Each is a discrete distribution where $\phi $ can take on only values 1 or 2. Note that the probability mass of a given value of $\phi $ for the pooled distribution falls in between the probability masses of the induced and direct distributions for that value of $\phi $.\relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces  Comparing the probability mass values of the direct, induced, and pooled distributions on $\phi $.\relax }}{16}{table.caption.13}\protected@file@percent }
\newlabel{tab:unnamed-chunk-15}{{3.2}{16}{Comparing the probability mass values of the direct, induced, and pooled distributions on $\phi $.\relax }{table.caption.13}{}}
\newlabel{table:table-pooled}{{3.2}{16}{Comparing the probability mass values of the direct, induced, and pooled distributions on $\phi $.\relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}General Solution for the Discrete Case}{17}{subsection.3.2.2}\protected@file@percent }
\newlabel{general-solution-for-the-discrete-case}{{3.2.2}{17}{General Solution for the Discrete Case}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}General Solution for the Continuous Case}{17}{subsection.3.2.3}\protected@file@percent }
\newlabel{general-solution-for-the-continuous-case}{{3.2.3}{17}{General Solution for the Continuous Case}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Implementation through the Sampling-Importance-Resampling Algorithm}{18}{subsection.3.2.4}\protected@file@percent }
\newlabel{implementation-through-the-sampling-importance-resampling-algorithm}{{3.2.4}{18}{Implementation through the Sampling-Importance-Resampling Algorithm}{subsection.3.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Bayesian Melding Applied to COVID-19 Misclassification}{19}{section.3.3}\protected@file@percent }
\newlabel{meld}{{3.3}{19}{Bayesian Melding Applied to COVID-19 Misclassification}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Sampling from the defined distributions of $\alpha $, $\beta $, and $\Pr (S_1|\text  {untested})$. $\Pr (S_1|\text  {untested})$ must be less than 1 since it is a probability, but $\alpha $ and $\beta $ are ratios of probabilities, so they do not have this constraint. Since it is plausible that $\alpha = \frac  {Pr(\text  {test}_+|\text  {untested}, S_1)}{\Pr (\text  {test}_+|\text  {tested})}$ could take on values larger than 1, we specify $\alpha $ as a gamma distribution. The others are beta distributions.\relax }}{20}{figure.caption.15}\protected@file@percent }
\newlabel{fig:theta}{{3.3}{20}{Sampling from the defined distributions of $\alpha $, $\beta $, and $\Pr (S_1|\text {untested})$. $\Pr (S_1|\text {untested})$ must be less than 1 since it is a probability, but $\alpha $ and $\beta $ are ratios of probabilities, so they do not have this constraint. Since it is plausible that $\alpha = \frac {Pr(\text {test}_+|\text {untested}, S_1)}{\Pr (\text {test}_+|\text {tested})}$ could take on values larger than 1, we specify $\alpha $ as a gamma distribution. The others are beta distributions.\relax }{figure.caption.15}{}}
\newlabel{fig:create-theta}{{3.3}{20}{Sampling from the defined distributions of $\alpha $, $\beta $, and $\Pr (S_1|\text {untested})$. $\Pr (S_1|\text {untested})$ must be less than 1 since it is a probability, but $\alpha $ and $\beta $ are ratios of probabilities, so they do not have this constraint. Since it is plausible that $\alpha = \frac {Pr(\text {test}_+|\text {untested}, S_1)}{\Pr (\text {test}_+|\text {tested})}$ could take on values larger than 1, we specify $\alpha $ as a gamma distribution. The others are beta distributions.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The induced prior is generated by computing $M(\theta )$ for sampled values of $\theta $ and estimating the density. The direct prior is informed based on meta-analyses on the asymptomatic rate of COVID-19, which generally support values between 0.3 and 0.6. We see here that there is substantial disagreement between the priors, where the induced prior places much more density near 1, while the mode of the direct prior is close to 0.35. This disagreement is a key part of the motivation for Bayesian melding -- we want to constrain our sampled values of $\alpha ,\beta ,$ and $\Pr (S_1|\text  {untested})$ to be in accordance with information on the asymptomatic rate of COVID-19.\relax }}{21}{figure.caption.16}\protected@file@percent }
\newlabel{fig:prior-induced}{{3.4}{21}{The induced prior is generated by computing $M(\theta )$ for sampled values of $\theta $ and estimating the density. The direct prior is informed based on meta-analyses on the asymptomatic rate of COVID-19, which generally support values between 0.3 and 0.6. We see here that there is substantial disagreement between the priors, where the induced prior places much more density near 1, while the mode of the direct prior is close to 0.35. This disagreement is a key part of the motivation for Bayesian melding -- we want to constrain our sampled values of $\alpha ,\beta ,$ and $\Pr (S_1|\text {untested})$ to be in accordance with information on the asymptomatic rate of COVID-19.\relax }{figure.caption.16}{}}
\newlabel{fig:unnamed-chunk-18}{{3.4}{21}{The induced prior is generated by computing $M(\theta )$ for sampled values of $\theta $ and estimating the density. The direct prior is informed based on meta-analyses on the asymptomatic rate of COVID-19, which generally support values between 0.3 and 0.6. We see here that there is substantial disagreement between the priors, where the induced prior places much more density near 1, while the mode of the direct prior is close to 0.35. This disagreement is a key part of the motivation for Bayesian melding -- we want to constrain our sampled values of $\alpha ,\beta ,$ and $\Pr (S_1|\text {untested})$ to be in accordance with information on the asymptomatic rate of COVID-19.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Pooling}{21}{subsection.3.3.1}\protected@file@percent }
\newlabel{pooling}{{3.3.1}{21}{Pooling}{subsection.3.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces  Comparing the sampled distributions of $\alpha ,\beta $, and $\Pr (S_1|\text  {untested})$ to the distributions after melding, when we have resampled these distributions with weights such that when we apply $M$ to the resample, we obtain a distribution of $\phi $ that is the log pool of the direct and induced priors on $\phi $.\relax }}{23}{figure.caption.18}\protected@file@percent }
\newlabel{fig:melded}{{3.5}{23}{Comparing the sampled distributions of $\alpha ,\beta $, and $\Pr (S_1|\text {untested})$ to the distributions after melding, when we have resampled these distributions with weights such that when we apply $M$ to the resample, we obtain a distribution of $\phi $ that is the log pool of the direct and induced priors on $\phi $.\relax }{figure.caption.18}{}}
\newlabel{fig:unnamed-chunk-19}{{3.5}{23}{Comparing the sampled distributions of $\alpha ,\beta $, and $\Pr (S_1|\text {untested})$ to the distributions after melding, when we have resampled these distributions with weights such that when we apply $M$ to the resample, we obtain a distribution of $\phi $ that is the log pool of the direct and induced priors on $\phi $.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Impact of Applying Melding on Corrected Estimates}{23}{subsection.3.3.2}\protected@file@percent }
\newlabel{impact-of-applying-melding-on-corrected-estimates}{{3.3.2}{23}{Impact of Applying Melding on Corrected Estimates}{subsection.3.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Comparing the final corrected estimates we obtain when using the melded distributions on $\alpha $, $\beta $, and $\Pr (S_1|\text  {untested})$ to those we obtain when omitting the melding step. We see the upper bounds when we \emph  {do not} apply melding are substantially higher. Referring back to Figure \ref {fig:melded}, we can see how the melded distributions contribute to this difference. In particular, the melded density of $\beta $ has higher density at smaller values than the distribution pre-melding, which reduces the estimates of unobserved infections.\relax }}{24}{figure.caption.19}\protected@file@percent }
\newlabel{fig:suffolkmelding}{{3.6}{24}{Comparing the final corrected estimates we obtain when using the melded distributions on $\alpha $, $\beta $, and $\Pr (S_1|\text {untested})$ to those we obtain when omitting the melding step. We see the upper bounds when we \emph {do not} apply melding are substantially higher. Referring back to Figure \ref {fig:melded}, we can see how the melded distributions contribute to this difference. In particular, the melded density of $\beta $ has higher density at smaller values than the distribution pre-melding, which reduces the estimates of unobserved infections.\relax }{figure.caption.19}{}}
\newlabel{fig:unnamed-chunk-21}{{3.6}{24}{Comparing the final corrected estimates we obtain when using the melded distributions on $\alpha $, $\beta $, and $\Pr (S_1|\text {untested})$ to those we obtain when omitting the melding step. We see the upper bounds when we \emph {do not} apply melding are substantially higher. Referring back to Figure \ref {fig:melded}, we can see how the melded distributions contribute to this difference. In particular, the melded density of $\beta $ has higher density at smaller values than the distribution pre-melding, which reduces the estimates of unobserved infections.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Derivation of \(M\)}{24}{subsection.3.3.3}\protected@file@percent }
\newlabel{derivation}{{3.3.3}{24}{\texorpdfstring {Derivation of \(M\)}{Derivation of M}}{subsection.3.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Sampling-Importance-Resampling Algorithm}{27}{section.3.4}\protected@file@percent }
\newlabel{sampling}{{3.4}{27}{Sampling-Importance-Resampling Algorithm}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Overview}{27}{subsection.3.4.1}\protected@file@percent }
\newlabel{overview-1}{{3.4.1}{27}{Overview}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Proof that Algorithm Obtains Approximate Sample from Target Distribution}{28}{subsection.3.4.2}\protected@file@percent }
\newlabel{proof}{{3.4.2}{28}{Proof that Algorithm Obtains Approximate Sample from Target Distribution}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example 1:}{30}{section*.20}\protected@file@percent }
\newlabel{example-1}{{3.4.2}{30}{Example 1:}{section*.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces  The distribution in blue is the exponential random variable $Y \sim Exp(0.2)$. Then, we take a weighted sample of $Y$ with weights that are directly proportional to $Y$, that is, $h(y)=y$. The resulting distribution is in gold. The weighted sample is we obtain the gamma distribution Gamma(2, 0.2), which is the product of the probability density function of $Y$ and the function $h$.\relax }}{30}{figure.caption.21}\protected@file@percent }
\newlabel{fig:ex12}{{3.7}{30}{The distribution in blue is the exponential random variable $Y \sim Exp(0.2)$. Then, we take a weighted sample of $Y$ with weights that are directly proportional to $Y$, that is, $h(y)=y$. The resulting distribution is in gold. The weighted sample is we obtain the gamma distribution Gamma(2, 0.2), which is the product of the probability density function of $Y$ and the function $h$.\relax }{figure.caption.21}{}}
\newlabel{fig:unnamed-chunk-23}{{3.7}{30}{The distribution in blue is the exponential random variable $Y \sim Exp(0.2)$. Then, we take a weighted sample of $Y$ with weights that are directly proportional to $Y$, that is, $h(y)=y$. The resulting distribution is in gold. The weighted sample is we obtain the gamma distribution Gamma(2, 0.2), which is the product of the probability density function of $Y$ and the function $h$.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example 2:}{31}{section*.22}\protected@file@percent }
\newlabel{example-2}{{3.4.2}{31}{Example 2:}{section*.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The distribution of an exponential random variable $Y \sim Exp(0.2)$ is in blue. After we obtain a weighted sample from $Y$ by sampling with weights defined by $h(y) e^{-\lambda y}$, we see the resulting distribution (in gold) is proportional to the distribution $Exp(2\lambda )$, as we see by comparing the distribution of the resample to the theoretical density of $Exp(2\lambda )$ is shown in red.\relax }}{31}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ex22}{{3.8}{31}{The distribution of an exponential random variable $Y \sim Exp(0.2)$ is in blue. After we obtain a weighted sample from $Y$ by sampling with weights defined by $h(y) e^{-\lambda y}$, we see the resulting distribution (in gold) is proportional to the distribution $Exp(2\lambda )$, as we see by comparing the distribution of the resample to the theoretical density of $Exp(2\lambda )$ is shown in red.\relax }{figure.caption.23}{}}
\newlabel{fig:unnamed-chunk-25}{{3.8}{31}{The distribution of an exponential random variable $Y \sim Exp(0.2)$ is in blue. After we obtain a weighted sample from $Y$ by sampling with weights defined by $h(y) e^{-\lambda y}$, we see the resulting distribution (in gold) is proportional to the distribution $Exp(2\lambda )$, as we see by comparing the distribution of the resample to the theoretical density of $Exp(2\lambda )$ is shown in red.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Obtaining Logarithmic Pooled Distribution with the Sampling-Importance-Resampling Algorithm}{32}{subsection.3.4.3}\protected@file@percent }
\newlabel{logpooled}{{3.4.3}{32}{Obtaining Logarithmic Pooled Distribution with the Sampling-Importance-Resampling Algorithm}{subsection.3.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Implications of the Sample Size and Resample Size}{32}{subsection.3.4.4}\protected@file@percent }
\newlabel{presamp}{{3.4.4}{32}{Implications of the Sample Size and Resample Size}{subsection.3.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Changing the initial sample size while keeping the posterior sample size constant at 5,000. We consider initial sample sizes $5 \times 10^3, 1 \times 10^4, 5 \times 10^4, \text  { and } 1\times 10^5$. We see in this figure that as we increase the initial sample size, the estimated density (in blue) becomes closer to the theoretical density shown in red.\relax }}{33}{figure.caption.24}\protected@file@percent }
\newlabel{fig:prepostsamp}{{3.9}{33}{Changing the initial sample size while keeping the posterior sample size constant at 5,000. We consider initial sample sizes $5 \times 10^3, 1 \times 10^4, 5 \times 10^4, \text { and } 1\times 10^5$. We see in this figure that as we increase the initial sample size, the estimated density (in blue) becomes closer to the theoretical density shown in red.\relax }{figure.caption.24}{}}
\newlabel{fig:pre-post-fig}{{3.9}{33}{Changing the initial sample size while keeping the posterior sample size constant at 5,000. We consider initial sample sizes $5 \times 10^3, 1 \times 10^4, 5 \times 10^4, \text { and } 1\times 10^5$. We see in this figure that as we increase the initial sample size, the estimated density (in blue) becomes closer to the theoretical density shown in red.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces  Here, we see the effect of the initial sample size, when keeping the posterior sample size constant. The effect is compounded by the use of a truncated density for $P(S_0|\text  {test}_+,\text  {untested})$, which restricts the support of the pooled distribution. This restricted support can lead to sampling a single observation many times, resulting in the irregularities we see in the distributions, particularly in the first panel. Increasing the sample size, and, as such increasing the ratio of the sample size to the resample size, does help in reducing these irregularities.\relax }}{34}{figure.caption.25}\protected@file@percent }
\newlabel{fig:trunc}{{3.10}{34}{Here, we see the effect of the initial sample size, when keeping the posterior sample size constant. The effect is compounded by the use of a truncated density for $P(S_0|\text {test}_+,\text {untested})$, which restricts the support of the pooled distribution. This restricted support can lead to sampling a single observation many times, resulting in the irregularities we see in the distributions, particularly in the first panel. Increasing the sample size, and, as such increasing the ratio of the sample size to the resample size, does help in reducing these irregularities.\relax }{figure.caption.25}{}}
\newlabel{fig:unnamed-chunk-29}{{3.10}{34}{Here, we see the effect of the initial sample size, when keeping the posterior sample size constant. The effect is compounded by the use of a truncated density for $P(S_0|\text {test}_+,\text {untested})$, which restricts the support of the pooled distribution. This restricted support can lead to sampling a single observation many times, resulting in the irregularities we see in the distributions, particularly in the first panel. Increasing the sample size, and, as such increasing the ratio of the sample size to the resample size, does help in reducing these irregularities.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}LOESS Smoothing}{35}{section.3.5}\protected@file@percent }
\newlabel{loess-smoothing}{{3.5}{35}{LOESS Smoothing}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Introduction}{35}{subsection.3.5.1}\protected@file@percent }
\newlabel{introduction-1}{{3.5.1}{35}{Introduction}{subsection.3.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces LOESS curve fitted with a span of 0.2. \relax }}{35}{figure.caption.26}\protected@file@percent }
\newlabel{fig:loess}{{3.11}{35}{LOESS curve fitted with a span of 0.2. \relax }{figure.caption.26}{}}
\newlabel{fig:unnamed-chunk-30}{{3.11}{35}{LOESS curve fitted with a span of 0.2. \relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces \relax }}{36}{figure.caption.27}\protected@file@percent }
\newlabel{fig:smooth-spans}{{3.12}{36}{\relax }{figure.caption.27}{}}
\newlabel{fig:unnamed-chunk-31}{{3.12}{36}{\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Kernel Density Estimation}{38}{section.3.6}\protected@file@percent }
\newlabel{kernel-density-estimation}{{3.6}{38}{Kernel Density Estimation}{section.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Overview}{38}{subsection.3.6.1}\protected@file@percent }
\newlabel{overview-2}{{3.6.1}{38}{Overview}{subsection.3.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Kernel density estimation with different values of the smoothing parameter $h$. We see that the effect of increasing the bandwidth $h$ is that larger values result in smoother curves, while smaller values result in curves that follow the histogram more closely.\relax }}{38}{figure.caption.28}\protected@file@percent }
\newlabel{fig:kernel}{{3.13}{38}{Kernel density estimation with different values of the smoothing parameter $h$. We see that the effect of increasing the bandwidth $h$ is that larger values result in smoother curves, while smaller values result in curves that follow the histogram more closely.\relax }{figure.caption.28}{}}
\newlabel{fig:unnamed-chunk-32}{{3.13}{38}{Kernel density estimation with different values of the smoothing parameter $h$. We see that the effect of increasing the bandwidth $h$ is that larger values result in smoother curves, while smaller values result in curves that follow the histogram more closely.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Bounded Density Estimation}{39}{subsection.3.6.2}\protected@file@percent }
\newlabel{bounded-density-estimation}{{3.6.2}{39}{Bounded Density Estimation}{subsection.3.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Comparing the performance of Gaussian density estimation for beta distributions of various shapes. The Gaussian density estimate is shown in teal, while the theoretical density is in red. For the shapes included here, the Gaussian density estimate is a reasonable approximation of the true density.\relax }}{40}{figure.caption.29}\protected@file@percent }
\newlabel{fig:gaus}{{3.14}{40}{Comparing the performance of Gaussian density estimation for beta distributions of various shapes. The Gaussian density estimate is shown in teal, while the theoretical density is in red. For the shapes included here, the Gaussian density estimate is a reasonable approximation of the true density.\relax }{figure.caption.29}{}}
\newlabel{fig:unnamed-chunk-35}{{3.14}{40}{Comparing the performance of Gaussian density estimation for beta distributions of various shapes. The Gaussian density estimate is shown in teal, while the theoretical density is in red. For the shapes included here, the Gaussian density estimate is a reasonable approximation of the true density.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 4: Definition of Prior Distributions for Bias Parameters}{41}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{defpriors}{{4}{41}{Definition of Prior Distributions for Bias Parameters}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Background on the Beta Distribution}{41}{section.4.1}\protected@file@percent }
\newlabel{background-on-the-beta-distribution}{{4.1}{41}{Background on the Beta Distribution}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces By changing the values of parameters of the parameters $a$ and $b$ of the beta distribution, we see that a variety of shapes are possible.\relax }}{41}{figure.caption.30}\protected@file@percent }
\newlabel{fig:beta-flexible}{{4.1}{41}{By changing the values of parameters of the parameters $a$ and $b$ of the beta distribution, we see that a variety of shapes are possible.\relax }{figure.caption.30}{}}
\newlabel{fig:unnamed-chunk-37}{{4.1}{41}{By changing the values of parameters of the parameters $a$ and $b$ of the beta distribution, we see that a variety of shapes are possible.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Background on the Gamma Distribution}{42}{section.4.2}\protected@file@percent }
\newlabel{background-on-the-gamma-distribution}{{4.2}{42}{Background on the Gamma Distribution}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Altering the parameters for the shape and scale of the gamma distribution yields a variety of possible shapes of densities defined on $(0,\infty )$.\relax }}{43}{figure.caption.31}\protected@file@percent }
\newlabel{fig:gamma-shapes}{{4.2}{43}{Altering the parameters for the shape and scale of the gamma distribution yields a variety of possible shapes of densities defined on $(0,\infty )$.\relax }{figure.caption.31}{}}
\newlabel{fig:unnamed-chunk-39}{{4.2}{43}{Altering the parameters for the shape and scale of the gamma distribution yields a variety of possible shapes of densities defined on $(0,\infty )$.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Definition of Prior Distributions for Incomplete Testing Correction}{44}{section.4.3}\protected@file@percent }
\newlabel{definition-of-prior-distributions-for-incomplete-testing-correction}{{4.3}{44}{Definition of Prior Distributions for Incomplete Testing Correction}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Defining \(P(S_1|\text  {untested})\)}{44}{subsection.4.3.1}\protected@file@percent }
\newlabel{defining-ps_1textuntested}{{4.3.1}{44}{\texorpdfstring {Defining \(P(S_1|\text {untested})\)}{Defining P(S\_1\textbar \textbackslash text\{untested\})}}{subsection.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The specified prior for $Pr(S_1|\text  {untested})$, where $Pr(S_1|\text  {untested}) \sim Beta(1.7,55)$, with a mean at 0.03 and standard deviation 0.0225.\relax }}{44}{figure.caption.32}\protected@file@percent }
\newlabel{fig:prior-s-untested}{{4.3}{44}{The specified prior for $Pr(S_1|\text {untested})$, where $Pr(S_1|\text {untested}) \sim Beta(1.7,55)$, with a mean at 0.03 and standard deviation 0.0225.\relax }{figure.caption.32}{}}
\newlabel{fig:unnamed-chunk-42}{{4.3}{44}{The specified prior for $Pr(S_1|\text {untested})$, where $Pr(S_1|\text {untested}) \sim Beta(1.7,55)$, with a mean at 0.03 and standard deviation 0.0225.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Defining \(\alpha \)}{45}{subsection.4.3.2}\protected@file@percent }
\newlabel{defining-alpha}{{4.3.2}{45}{\texorpdfstring {Defining \(\alpha \)}{Defining \textbackslash alpha}}{subsection.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The specified prior for $\alpha $, where $\alpha $ is the ratio $\dfrac  {\Pr (\text  {test}_+|S_1, \text  {untested})}{\Pr (\text  {test}_+|\text  {tested})}$. The distribution is defined such that mean is at 0.95 and standard deviation 0.08.\relax }}{45}{figure.caption.33}\protected@file@percent }
\newlabel{fig:alpha-dist}{{4.4}{45}{The specified prior for $\alpha $, where $\alpha $ is the ratio $\dfrac {\Pr (\text {test}_+|S_1, \text {untested})}{\Pr (\text {test}_+|\text {tested})}$. The distribution is defined such that mean is at 0.95 and standard deviation 0.08.\relax }{figure.caption.33}{}}
\newlabel{fig:unnamed-chunk-45}{{4.4}{45}{The specified prior for $\alpha $, where $\alpha $ is the ratio $\dfrac {\Pr (\text {test}_+|S_1, \text {untested})}{\Pr (\text {test}_+|\text {tested})}$. The distribution is defined such that mean is at 0.95 and standard deviation 0.08.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Defining \(\beta \)}{45}{subsection.4.3.3}\protected@file@percent }
\newlabel{defining-beta}{{4.3.3}{45}{\texorpdfstring {Defining \(\beta \)}{Defining \textbackslash beta}}{subsection.4.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The specified prior for $\beta $, where $\beta $ is the ratio $\dfrac  {\Pr (\text  {test}_+|S_0, \text  {untested})}{\Pr (\text  {test}_+|\text  {tested})}$. The distribution is defined such that mean is at 0.15 and standard deviation 0.09.\relax }}{46}{figure.caption.34}\protected@file@percent }
\newlabel{fig:beta-dist}{{4.5}{46}{The specified prior for $\beta $, where $\beta $ is the ratio $\dfrac {\Pr (\text {test}_+|S_0, \text {untested})}{\Pr (\text {test}_+|\text {tested})}$. The distribution is defined such that mean is at 0.15 and standard deviation 0.09.\relax }{figure.caption.34}{}}
\newlabel{fig:unnamed-chunk-46}{{4.5}{46}{The specified prior for $\beta $, where $\beta $ is the ratio $\dfrac {\Pr (\text {test}_+|S_0, \text {untested})}{\Pr (\text {test}_+|\text {tested})}$. The distribution is defined such that mean is at 0.15 and standard deviation 0.09.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Defining \(P(S_0|\text  {test}_+,\text  {untested})\)}{46}{subsection.4.3.4}\protected@file@percent }
\newlabel{defining-ps_0texttest_textuntested}{{4.3.4}{46}{\texorpdfstring {Defining \(P(S_0|\text {test}_+,\text {untested})\)}{Defining P(S\_0\textbar \textbackslash text\{test\}\_+,\textbackslash text\{untested\})}}{subsection.4.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The specified prior for $\Pr (S_0|\text  {test}_+,\text  {tested})$, which represents the asymptomatic rate of infection among the untested population. The distribution is defined such that mean is at 0.4 and the standard deviation is 0.1225.\relax }}{47}{figure.caption.35}\protected@file@percent }
\newlabel{fig:asymp-dist}{{4.6}{47}{The specified prior for $\Pr (S_0|\text {test}_+,\text {tested})$, which represents the asymptomatic rate of infection among the untested population. The distribution is defined such that mean is at 0.4 and the standard deviation is 0.1225.\relax }{figure.caption.35}{}}
\newlabel{fig:unnamed-chunk-47}{{4.6}{47}{The specified prior for $\Pr (S_0|\text {test}_+,\text {tested})$, which represents the asymptomatic rate of infection among the untested population. The distribution is defined such that mean is at 0.4 and the standard deviation is 0.1225.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Definition of Priors for Test Inaccuracy Correction}{48}{section.4.4}\protected@file@percent }
\newlabel{definition-of-priors-for-test-inaccuracy-correction}{{4.4}{48}{Definition of Priors for Test Inaccuracy Correction}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Defining Test Sensitivity (\(S_e\))}{48}{subsection.4.4.1}\protected@file@percent }
\newlabel{defining-test-sensitivity-s_e}{{4.4.1}{48}{\texorpdfstring {Defining Test Sensitivity (\(S_e\))}{Defining Test Sensitivity (S\_e)}}{subsection.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  The distribution for PCR test sensitivity, defined such that $S_e \sim \text  {TBeta}(a= 4.20, b= 1.05)$.\relax }}{48}{figure.caption.36}\protected@file@percent }
\newlabel{fig:dist-sens}{{4.7}{48}{The distribution for PCR test sensitivity, defined such that $S_e \sim \text {TBeta}(a= 4.20, b= 1.05)$.\relax }{figure.caption.36}{}}
\newlabel{fig:unnamed-chunk-48}{{4.7}{48}{The distribution for PCR test sensitivity, defined such that $S_e \sim \text {TBeta}(a= 4.20, b= 1.05)$.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Variant proportions in the United States from genomic surveillance data collected by the CDC. Data is not available for time periods earlier than May 8, 2021.\relax }}{49}{figure.caption.37}\protected@file@percent }
\newlabel{fig:unnamed-chunk-50}{{4.8}{49}{Variant proportions in the United States from genomic surveillance data collected by the CDC. Data is not available for time periods earlier than May 8, 2021.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Defining Test Specificity (\(S_p\))}{49}{section.4.5}\protected@file@percent }
\newlabel{defining-test-specificity-s_p}{{4.5}{49}{\texorpdfstring {Defining Test Specificity (\(S_p\))}{Defining Test Specificity (S\_p)}}{section.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces  The distribution defined for PCR test specificity, defined such that $S_p = \sim \text  {TBeta}(a = 4998.50, b = 0.25)$. This prior is informed by the CDC 2019-nCoV Real-Time RT-PCR Diagnostic Panel.\relax }}{50}{figure.caption.38}\protected@file@percent }
\newlabel{fig:dist-spec}{{4.9}{50}{The distribution defined for PCR test specificity, defined such that $S_p = \sim \text {TBeta}(a = 4998.50, b = 0.25)$. This prior is informed by the CDC 2019-nCoV Real-Time RT-PCR Diagnostic Panel.\relax }{figure.caption.38}{}}
\newlabel{fig:unnamed-chunk-51}{{4.9}{50}{The distribution defined for PCR test specificity, defined such that $S_p = \sim \text {TBeta}(a = 4998.50, b = 0.25)$. This prior is informed by the CDC 2019-nCoV Real-Time RT-PCR Diagnostic Panel.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Exploration of the Implications of Changes in the Bias Parameters}{50}{section.4.6}\protected@file@percent }
\newlabel{exploration-of-the-implications-of-changes-in-the-bias-parameters}{{4.6}{50}{Exploration of the Implications of Changes in the Bias Parameters}{section.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Correction for Incomplete Testing}{50}{section.4.7}\protected@file@percent }
\newlabel{correction-for-incomplete-testing}{{4.7}{50}{Correction for Incomplete Testing}{section.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Correction for Diagnostic Test Inaccuracy}{51}{section.4.8}\protected@file@percent }
\newlabel{correct-test-inaccuracy}{{4.8}{51}{Correction for Diagnostic Test Inaccuracy}{section.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}Derivation of Formula for Correction for Diagnostic Test Inaccuracy}{51}{subsection.4.8.1}\protected@file@percent }
\newlabel{derivation-of-formula-for-correction-for-diagnostic-test-inaccuracy}{{4.8.1}{51}{Derivation of Formula for Correction for Diagnostic Test Inaccuracy}{subsection.4.8.1}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 5: Details of Implementation}{55}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{details-of-implementation}{{5}{55}{Details of Implementation}{chapter.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Description of each implementation of probabilistic bias analysis. Version 1 does not inform priors based on the COVID-19 Trends and Impact Survey, while versions 2-4 do utilize the survey data.\relax }}{55}{figure.caption.40}\protected@file@percent }
\newlabel{fig:priors-versions-table}{{5.1}{55}{Description of each implementation of probabilistic bias analysis. Version 1 does not inform priors based on the COVID-19 Trends and Impact Survey, while versions 2-4 do utilize the survey data.\relax }{figure.caption.40}{}}
\newlabel{fig:unnamed-chunk-53}{{5.1}{55}{Description of each implementation of probabilistic bias analysis. Version 1 does not inform priors based on the COVID-19 Trends and Impact Survey, while versions 2-4 do utilize the survey data.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Version 1: Priors Do Not Vary by State or Date}{56}{section.5.1}\protected@file@percent }
\newlabel{version-1-priors-do-not-vary-by-state-or-date}{{5.1}{56}{Version 1: Priors Do Not Vary by State or Date}{section.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces As the first step of the probabilistic bias analysis, we sample $m$ observations from the defined priors $\theta = \{ \alpha , \beta , \Pr (S_1| \text  {untested})\}$.\relax }}{56}{figure.caption.41}\protected@file@percent }
\newlabel{fig:sample-priors}{{5.2}{56}{As the first step of the probabilistic bias analysis, we sample $m$ observations from the defined priors $\theta = \{ \alpha , \beta , \Pr (S_1| \text {untested})\}$.\relax }{figure.caption.41}{}}
\newlabel{fig:unnamed-chunk-55}{{5.2}{56}{As the first step of the probabilistic bias analysis, we sample $m$ observations from the defined priors $\theta = \{ \alpha , \beta , \Pr (S_1| \text {untested})\}$.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The full set of priors used in the probabilistic bias analysis. The first row is our sampled values of $\theta $, before and after melding. The post-melding distributions are what we use as inputs to the probabilistic bias analysis. The second row is $\Pr (S_0|\text  {test}_+, \text  {untested})$, which is a part of the melding process that enables us to incorporate information on the asymptomatic rate to inform the definitions of $\theta $; however, we do not use the parameter $\Pr (S_0|\text  {test}_+, \text  {untested})$ directly in the bias correction; its only role is in the melding step.\relax }}{57}{figure.caption.42}\protected@file@percent }
\newlabel{fig:melded-all-together}{{5.3}{57}{The full set of priors used in the probabilistic bias analysis. The first row is our sampled values of $\theta $, before and after melding. The post-melding distributions are what we use as inputs to the probabilistic bias analysis. The second row is $\Pr (S_0|\text {test}_+, \text {untested})$, which is a part of the melding process that enables us to incorporate information on the asymptomatic rate to inform the definitions of $\theta $; however, we do not use the parameter $\Pr (S_0|\text {test}_+, \text {untested})$ directly in the bias correction; its only role is in the melding step.\relax }{figure.caption.42}{}}
\newlabel{fig:unnamed-chunk-58}{{5.3}{57}{The full set of priors used in the probabilistic bias analysis. The first row is our sampled values of $\theta $, before and after melding. The post-melding distributions are what we use as inputs to the probabilistic bias analysis. The second row is $\Pr (S_0|\text {test}_+, \text {untested})$, which is a part of the melding process that enables us to incorporate information on the asymptomatic rate to inform the definitions of $\theta $; however, we do not use the parameter $\Pr (S_0|\text {test}_+, \text {untested})$ directly in the bias correction; its only role is in the melding step.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Here, we consider Suffolk County in a specific two-week interval. By sampling from the bias parameters, melding, correcting for incomplete testing, and then correcting for test inaccuracy, we obtain a distribution of estimated infections for the two-week interval. We can summarize this distribution with a 95\% simulation interval.\relax }}{59}{figure.caption.43}\protected@file@percent }
\newlabel{fig:correctedsuffolk}{{5.4}{59}{Here, we consider Suffolk County in a specific two-week interval. By sampling from the bias parameters, melding, correcting for incomplete testing, and then correcting for test inaccuracy, we obtain a distribution of estimated infections for the two-week interval. We can summarize this distribution with a 95\% simulation interval.\relax }{figure.caption.43}{}}
\newlabel{fig:unnamed-chunk-59}{{5.4}{59}{Here, we consider Suffolk County in a specific two-week interval. By sampling from the bias parameters, melding, correcting for incomplete testing, and then correcting for test inaccuracy, we obtain a distribution of estimated infections for the two-week interval. We can summarize this distribution with a 95\% simulation interval.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Here, we show how we visualize the 95\% simulation intervals like the one shown in \ref {fig:correctedsuffolk}, which is highlighted in red. Presenting these intervals over time for a given location is often how we present the results of the probabilistic bias analysis.\relax }}{59}{figure.caption.44}\protected@file@percent }
\newlabel{fig:corrected-suffolk-over-time}{{5.5}{59}{Here, we show how we visualize the 95\% simulation intervals like the one shown in \ref {fig:correctedsuffolk}, which is highlighted in red. Presenting these intervals over time for a given location is often how we present the results of the probabilistic bias analysis.\relax }{figure.caption.44}{}}
\newlabel{fig:unnamed-chunk-60}{{5.5}{59}{Here, we show how we visualize the 95\% simulation intervals like the one shown in \ref {fig:correctedsuffolk}, which is highlighted in red. Presenting these intervals over time for a given location is often how we present the results of the probabilistic bias analysis.\relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Version 2-4: Allowing Some Prior Parameters to Vary}{60}{section.5.2}\protected@file@percent }
\newlabel{version-2-4-allowing-some-prior-parameters-to-vary}{{5.2}{60}{Version 2-4: Allowing Some Prior Parameters to Vary}{section.5.2}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 6: Comparison to the Covidestim Model}{61}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{comparison-to-the-covidestim-model}{{6}{61}{Comparison to the Covidestim Model}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Overview}{61}{section.6.1}\protected@file@percent }
\newlabel{overview-3}{{6.1}{61}{Overview}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}The Covidestim Model}{61}{section.6.2}\protected@file@percent }
\newlabel{the-covidestim-model}{{6.2}{61}{The Covidestim Model}{section.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Assumptions}{62}{section.6.3}\protected@file@percent }
\newlabel{assumptions}{{6.3}{62}{Assumptions}{section.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Comparison to Serological Data}{63}{section.6.4}\protected@file@percent }
\newlabel{comparison-to-serological-data}{{6.4}{63}{Comparison to Serological Data}{section.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Limitations of this Comparison}{63}{subsection.6.4.1}\protected@file@percent }
\newlabel{lims}{{6.4.1}{63}{Limitations of this Comparison}{subsection.6.4.1}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 7: Results}{65}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{res}{{7}{65}{Results}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}State-level Results}{65}{section.7.1}\protected@file@percent }
\newlabel{state-level-results}{{7.1}{65}{State-level Results}{section.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces The screening test positivity over the overall test positivity from the COVID-19 Trends and Impact Survey, by state. For states where less than 40\% of observations were missing at the daily time step, the LOESS smoothed line is shown in red.\relax }}{66}{figure.caption.45}\protected@file@percent }
\newlabel{fig:statectis}{{7.1}{66}{The screening test positivity over the overall test positivity from the COVID-19 Trends and Impact Survey, by state. For states where less than 40\% of observations were missing at the daily time step, the LOESS smoothed line is shown in red.\relax }{figure.caption.45}{}}
\newlabel{fig:unnamed-chunk-62}{{7.1}{66}{The screening test positivity over the overall test positivity from the COVID-19 Trends and Impact Survey, by state. For states where less than 40\% of observations were missing at the daily time step, the LOESS smoothed line is shown in red.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces  The percent of the population experiencing COVID-19-like illness from the COVID-19 Trends and Impact Survey, by state. The LOESS smoothed line is shown in red. For the implementations of probabilistic bias analysis where we use this indicator to inform $\Pr (S_1|\text  {untested})$, we center the distribution of $\Pr (S_1|\text  {untested})$ at the smoothed value from the survey. We note that there is less missing data for this indicator than for $\beta $ (Figure \ref {fig:statectis}), for which we need both the screening positivity and overall test positivity.\relax }}{67}{figure.caption.46}\protected@file@percent }
\newlabel{fig:statectis-s-untested}{{7.2}{67}{The percent of the population experiencing COVID-19-like illness from the COVID-19 Trends and Impact Survey, by state. The LOESS smoothed line is shown in red. For the implementations of probabilistic bias analysis where we use this indicator to inform $\Pr (S_1|\text {untested})$, we center the distribution of $\Pr (S_1|\text {untested})$ at the smoothed value from the survey. We note that there is less missing data for this indicator than for $\beta $ (Figure \ref {fig:statectis}), for which we need both the screening positivity and overall test positivity.\relax }{figure.caption.46}{}}
\newlabel{fig:unnamed-chunk-63}{{7.2}{67}{The percent of the population experiencing COVID-19-like illness from the COVID-19 Trends and Impact Survey, by state. The LOESS smoothed line is shown in red. For the implementations of probabilistic bias analysis where we use this indicator to inform $\Pr (S_1|\text {untested})$, we center the distribution of $\Pr (S_1|\text {untested})$ at the smoothed value from the survey. We note that there is less missing data for this indicator than for $\beta $ (Figure \ref {fig:statectis}), for which we need both the screening positivity and overall test positivity.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces 95\% simulation intervals for each state and two-week interval. Only states with all four versions are included; this figure represents the first half of states with all four versions, and \ref {fig:state-results-2} represents thee second half. Each column represents a distinct implementation of the probabilistic bias analysis. The first is where priors do not vary by state or location; that is, priors are specified once and these same priors are used for all states and time inteervals considered. The second implementation centers the distribution of $\beta $ at the ratio of screening test positivity to overall test positivity from the COVID-19 Trends and Impact Survey. The third implementation centers the distribution of $\Pr (S_1|\text  {untested})$ at the percent of the population experiencing COVID-19-like illness. The fourth implementation centers both $\beta $ and $\Pr (S_1|\text  {untested})$ at the survey values.\relax }}{69}{figure.caption.47}\protected@file@percent }
\newlabel{fig:state-results-1}{{7.3}{69}{95\% simulation intervals for each state and two-week interval. Only states with all four versions are included; this figure represents the first half of states with all four versions, and \ref {fig:state-results-2} represents thee second half. Each column represents a distinct implementation of the probabilistic bias analysis. The first is where priors do not vary by state or location; that is, priors are specified once and these same priors are used for all states and time inteervals considered. The second implementation centers the distribution of $\beta $ at the ratio of screening test positivity to overall test positivity from the COVID-19 Trends and Impact Survey. The third implementation centers the distribution of $\Pr (S_1|\text {untested})$ at the percent of the population experiencing COVID-19-like illness. The fourth implementation centers both $\beta $ and $\Pr (S_1|\text {untested})$ at the survey values.\relax }{figure.caption.47}{}}
\newlabel{fig:unnamed-chunk-64}{{7.3}{69}{95\% simulation intervals for each state and two-week interval. Only states with all four versions are included; this figure represents the first half of states with all four versions, and \ref {fig:state-results-2} represents thee second half. Each column represents a distinct implementation of the probabilistic bias analysis. The first is where priors do not vary by state or location; that is, priors are specified once and these same priors are used for all states and time inteervals considered. The second implementation centers the distribution of $\beta $ at the ratio of screening test positivity to overall test positivity from the COVID-19 Trends and Impact Survey. The third implementation centers the distribution of $\Pr (S_1|\text {untested})$ at the percent of the population experiencing COVID-19-like illness. The fourth implementation centers both $\beta $ and $\Pr (S_1|\text {untested})$ at the survey values.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces  As in \ref {fig:state-results-1}, this figure contains the probabilistic bias analysis intervals for states where all four implementations were possible for the second half of states (where \ref {fig:state-results-1} corresonds to the first half). More detail on each column is discussed in \ref {fig:state-results-1}.\relax }}{70}{figure.caption.48}\protected@file@percent }
\newlabel{fig:state-results-2}{{7.4}{70}{As in \ref {fig:state-results-1}, this figure contains the probabilistic bias analysis intervals for states where all four implementations were possible for the second half of states (where \ref {fig:state-results-1} corresonds to the first half). More detail on each column is discussed in \ref {fig:state-results-1}.\relax }{figure.caption.48}{}}
\newlabel{fig:unnamed-chunk-65}{{7.4}{70}{As in \ref {fig:state-results-1}, this figure contains the probabilistic bias analysis intervals for states where all four implementations were possible for the second half of states (where \ref {fig:state-results-1} corresonds to the first half). More detail on each column is discussed in \ref {fig:state-results-1}.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Variant proportions for variants designated as Variant of Interest or Variant of Concern by the World Health Organization. We see Delta begins its rise in May 2021 and reaches an estimated proportion of 0.98 of sequenced infections by mid-August 2021. Omicron's rise occurs more quickly, beginning its increase throughout December and becoming almost entirely dominant by mid-January. Data source: SARS-CoV-2 Variant Proportions from Data.CDC.gov.\relax }}{71}{figure.caption.49}\protected@file@percent }
\newlabel{fig:variant-prop}{{7.5}{71}{Variant proportions for variants designated as Variant of Interest or Variant of Concern by the World Health Organization. We see Delta begins its rise in May 2021 and reaches an estimated proportion of 0.98 of sequenced infections by mid-August 2021. Omicron's rise occurs more quickly, beginning its increase throughout December and becoming almost entirely dominant by mid-January. Data source: SARS-CoV-2 Variant Proportions from Data.CDC.gov.\relax }{figure.caption.49}{}}
\newlabel{fig:unnamed-chunk-66}{{7.5}{71}{Variant proportions for variants designated as Variant of Interest or Variant of Concern by the World Health Organization. We see Delta begins its rise in May 2021 and reaches an estimated proportion of 0.98 of sequenced infections by mid-August 2021. Omicron's rise occurs more quickly, beginning its increase throughout December and becoming almost entirely dominant by mid-January. Data source: SARS-CoV-2 Variant Proportions from Data.CDC.gov.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Example Where July Peak is Larger in Probablistic Bias Analysis Intervals: Michigan}{72}{subsection.7.1.1}\protected@file@percent }
\newlabel{example-where-july-peak-is-larger-in-probablistic-bias-analysis-intervals-michigan}{{7.1.1}{72}{Example Where July Peak is Larger in Probablistic Bias Analysis Intervals: Michigan}{subsection.7.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Probabilistic intervals for Michigan along with the variant proportions for variants designated as Variant of Interest or Variant of Concern by the World Health Organization. These variant proportions are not specific to Michigan; the estimates are for the United States. The rise in Omicron corresponds to the dramatic increase in both the probabilistic bias intervals and Covidestim estimates in December of 2021 through January of 2022. We also see the increase in the Delta variant that precedes the Delta wave in the summer of 2021.\relax }}{72}{figure.caption.50}\protected@file@percent }
\newlabel{fig:michigan-variant}{{7.6}{72}{Probabilistic intervals for Michigan along with the variant proportions for variants designated as Variant of Interest or Variant of Concern by the World Health Organization. These variant proportions are not specific to Michigan; the estimates are for the United States. The rise in Omicron corresponds to the dramatic increase in both the probabilistic bias intervals and Covidestim estimates in December of 2021 through January of 2022. We also see the increase in the Delta variant that precedes the Delta wave in the summer of 2021.\relax }{figure.caption.50}{}}
\newlabel{fig:unnamed-chunk-67}{{7.6}{72}{Probabilistic intervals for Michigan along with the variant proportions for variants designated as Variant of Interest or Variant of Concern by the World Health Organization. These variant proportions are not specific to Michigan; the estimates are for the United States. The rise in Omicron corresponds to the dramatic increase in both the probabilistic bias intervals and Covidestim estimates in December of 2021 through January of 2022. We also see the increase in the Delta variant that precedes the Delta wave in the summer of 2021.\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces  Percent change in positive tests and the percent change in total tests from March 2021 through the end of February 2022. We see in the period from July through September that the positive tests increase at a higher rate than the total tests, which relates to the increase we see beginning in July in the probabilistic bias intervals.\relax }}{73}{figure.caption.51}\protected@file@percent }
\newlabel{fig:test-capacity}{{7.7}{73}{Percent change in positive tests and the percent change in total tests from March 2021 through the end of February 2022. We see in the period from July through September that the positive tests increase at a higher rate than the total tests, which relates to the increase we see beginning in July in the probabilistic bias intervals.\relax }{figure.caption.51}{}}
\newlabel{fig:unnamed-chunk-68}{{7.7}{73}{Percent change in positive tests and the percent change in total tests from March 2021 through the end of February 2022. We see in the period from July through September that the positive tests increase at a higher rate than the total tests, which relates to the increase we see beginning in July in the probabilistic bias intervals.\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Example Where Covidestim Intervals Lag Probabilistic Bias Intervals: Texas}{74}{subsection.7.1.2}\protected@file@percent }
\newlabel{example-where-covidestim-intervals-lag-probabilistic-bias-intervals-texas}{{7.1.2}{74}{Example Where Covidestim Intervals Lag Probabilistic Bias Intervals: Texas}{subsection.7.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces  Probabilistic bias analysis intervals for Texas across time. Each probabilistic bias interval is a 95\% simulation interval for the estimated infections for that entire 2-week period. In red are Covidestim estimates summed to be on the same biweekly time scale. Texas is one state where the Covidestim estimates appear to lag the probabilistic bias analysis for the Delta wave beginning in July. This is true for both the version that does not incorporate survey data from the COVID-19 Trends and Impact Survey, as well as the version that does, so the difference cannot be explained by the survey data alone.\relax }}{74}{figure.caption.52}\protected@file@percent }
\newlabel{fig:texas}{{7.8}{74}{Probabilistic bias analysis intervals for Texas across time. Each probabilistic bias interval is a 95\% simulation interval for the estimated infections for that entire 2-week period. In red are Covidestim estimates summed to be on the same biweekly time scale. Texas is one state where the Covidestim estimates appear to lag the probabilistic bias analysis for the Delta wave beginning in July. This is true for both the version that does not incorporate survey data from the COVID-19 Trends and Impact Survey, as well as the version that does, so the difference cannot be explained by the survey data alone.\relax }{figure.caption.52}{}}
\newlabel{fig:unnamed-chunk-69}{{7.8}{74}{Probabilistic bias analysis intervals for Texas across time. Each probabilistic bias interval is a 95\% simulation interval for the estimated infections for that entire 2-week period. In red are Covidestim estimates summed to be on the same biweekly time scale. Texas is one state where the Covidestim estimates appear to lag the probabilistic bias analysis for the Delta wave beginning in July. This is true for both the version that does not incorporate survey data from the COVID-19 Trends and Impact Survey, as well as the version that does, so the difference cannot be explained by the survey data alone.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces  Comparing the data sources for the probablistic bias analysis and the Covidestim model to look into the source of the lag observed in Texas, as shown in Figure \ref {fig:texas}. The two solid lines are the data sources: the data source for the probabilistic analysis is PCR tests from the CDC's Diagnostic Laboratory Testing Time series, while the data source for the Covidestim model is Johns Hopkins CSSE case counts. Each source is summed on the biweekly time scale. The test positivity is the positive tests from the CDC source over total tests for the two-week interval. The Johns Hopkins CSSE and CDC positive tests are largely concordant, so differences in data source do not appear to explain the lag for the delta wave in Texas. The test positivity, however, does clarifies the lag. The test positivity begins increasing in early June, before we see positive tests or cases increasing, due to total tests at first decreasing and then increasing, but not at the same rate as the positive tests (Supplementary Figure \ref {fig:test-capacity-all-states}) . This increase in test positivity is reflected in the probabalistic bias intervals in Figure \ref {fig:texas-source}, where increases corresponding to the Delta wave start begin earlier, in early to mid June, compared to July, where the increase is at about a two-week lag.\relax }}{75}{figure.caption.53}\protected@file@percent }
\newlabel{fig:texas-source}{{7.9}{75}{Comparing the data sources for the probablistic bias analysis and the Covidestim model to look into the source of the lag observed in Texas, as shown in Figure \ref {fig:texas}. The two solid lines are the data sources: the data source for the probabilistic analysis is PCR tests from the CDC's Diagnostic Laboratory Testing Time series, while the data source for the Covidestim model is Johns Hopkins CSSE case counts. Each source is summed on the biweekly time scale. The test positivity is the positive tests from the CDC source over total tests for the two-week interval. The Johns Hopkins CSSE and CDC positive tests are largely concordant, so differences in data source do not appear to explain the lag for the delta wave in Texas. The test positivity, however, does clarifies the lag. The test positivity begins increasing in early June, before we see positive tests or cases increasing, due to total tests at first decreasing and then increasing, but not at the same rate as the positive tests (Supplementary Figure \ref {fig:test-capacity-all-states}) . This increase in test positivity is reflected in the probabalistic bias intervals in Figure \ref {fig:texas-source}, where increases corresponding to the Delta wave start begin earlier, in early to mid June, compared to July, where the increase is at about a two-week lag.\relax }{figure.caption.53}{}}
\newlabel{fig:unnamed-chunk-70}{{7.9}{75}{Comparing the data sources for the probablistic bias analysis and the Covidestim model to look into the source of the lag observed in Texas, as shown in Figure \ref {fig:texas}. The two solid lines are the data sources: the data source for the probabilistic analysis is PCR tests from the CDC's Diagnostic Laboratory Testing Time series, while the data source for the Covidestim model is Johns Hopkins CSSE case counts. Each source is summed on the biweekly time scale. The test positivity is the positive tests from the CDC source over total tests for the two-week interval. The Johns Hopkins CSSE and CDC positive tests are largely concordant, so differences in data source do not appear to explain the lag for the delta wave in Texas. The test positivity, however, does clarifies the lag. The test positivity begins increasing in early June, before we see positive tests or cases increasing, due to total tests at first decreasing and then increasing, but not at the same rate as the positive tests (Supplementary Figure \ref {fig:test-capacity-all-states}) . This increase in test positivity is reflected in the probabalistic bias intervals in Figure \ref {fig:texas-source}, where increases corresponding to the Delta wave start begin earlier, in early to mid June, compared to July, where the increase is at about a two-week lag.\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Summarizing Concordance with Covidestim}{76}{subsection.7.1.3}\protected@file@percent }
\newlabel{summarizing-concordance-with-covidestim}{{7.1.3}{76}{Summarizing Concordance with Covidestim}{subsection.7.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces  To summarize the concordance with Covidestim for each state, we consider the proportion of all probabilistic bias intervals that contain the Covidestim median for that time interval, and the proportions where the Covidestim median falls above or below the interval. We see the implementation that centers the prior for $\Pr (S_1|\text  {untested})$ at the percent of COVID-19-like illness in the population is the most concordant with Covidestim.\relax }}{76}{figure.caption.54}\protected@file@percent }
\newlabel{fig:summarize-concordance-state}{{7.10}{76}{To summarize the concordance with Covidestim for each state, we consider the proportion of all probabilistic bias intervals that contain the Covidestim median for that time interval, and the proportions where the Covidestim median falls above or below the interval. We see the implementation that centers the prior for $\Pr (S_1|\text {untested})$ at the percent of COVID-19-like illness in the population is the most concordant with Covidestim.\relax }{figure.caption.54}{}}
\newlabel{fig:unnamed-chunk-71}{{7.10}{76}{To summarize the concordance with Covidestim for each state, we consider the proportion of all probabilistic bias intervals that contain the Covidestim median for that time interval, and the proportions where the Covidestim median falls above or below the interval. We see the implementation that centers the prior for $\Pr (S_1|\text {untested})$ at the percent of COVID-19-like illness in the population is the most concordant with Covidestim.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Ratio Between Estimated Infections and Observed Infections}{77}{section.7.2}\protected@file@percent }
\newlabel{ratio-between-estimated-infections-and-observed-infections}{{7.2}{77}{Ratio Between Estimated Infections and Observed Infections}{section.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces  The ratio of estimated infections to observed infections for each 2-week interval and each state, only considering the version of the priors that does not vary by state or time. States are ordered from highest to lowest by median ratio of estimated infections to observed infections over all 2-week intervals considered. The two-week intervals with highest ratios are in June 18, 2021 through July 16, 2021.\relax }}{78}{figure.caption.55}\protected@file@percent }
\newlabel{fig:ratio-est-observed}{{7.11}{78}{The ratio of estimated infections to observed infections for each 2-week interval and each state, only considering the version of the priors that does not vary by state or time. States are ordered from highest to lowest by median ratio of estimated infections to observed infections over all 2-week intervals considered. The two-week intervals with highest ratios are in June 18, 2021 through July 16, 2021.\relax }{figure.caption.55}{}}
\newlabel{fig:unnamed-chunk-72}{{7.11}{78}{The ratio of estimated infections to observed infections for each 2-week interval and each state, only considering the version of the priors that does not vary by state or time. States are ordered from highest to lowest by median ratio of estimated infections to observed infections over all 2-week intervals considered. The two-week intervals with highest ratios are in June 18, 2021 through July 16, 2021.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.12}{\ignorespaces Testing rate, calculated as the etotal number of tests for a 2-week interval in a state over the census population in that state, over time. The median across states for each two-week interval is shown in red. In relation to Figure \ref {fig:ratio-est-observed}, where we see the period where the ratio of estimated to observed infections is the highest in June 18, 2021 through July 16, 2021, we see here that testing rates across states are at a minimum during this time period.\relax }}{78}{figure.caption.56}\protected@file@percent }
\newlabel{fig:test-low-summer}{{7.12}{78}{Testing rate, calculated as the etotal number of tests for a 2-week interval in a state over the census population in that state, over time. The median across states for each two-week interval is shown in red. In relation to Figure \ref {fig:ratio-est-observed}, where we see the period where the ratio of estimated to observed infections is the highest in June 18, 2021 through July 16, 2021, we see here that testing rates across states are at a minimum during this time period.\relax }{figure.caption.56}{}}
\newlabel{fig:unnamed-chunk-73}{{7.12}{78}{Testing rate, calculated as the etotal number of tests for a 2-week interval in a state over the census population in that state, over time. The median across states for each two-week interval is shown in red. In relation to Figure \ref {fig:ratio-est-observed}, where we see the period where the ratio of estimated to observed infections is the highest in June 18, 2021 through July 16, 2021, we see here that testing rates across states are at a minimum during this time period.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.13}{\ignorespaces The ratio of estimated infections to observed infections for each state from December 31, 2021 through January 14, 2022; this time interval corresponds to the peak of the Omicron wave. States are ordered by the highest median ratio, which is shown in red.\relax }}{79}{figure.caption.57}\protected@file@percent }
\newlabel{fig:ratio-peak-omicron}{{7.13}{79}{The ratio of estimated infections to observed infections for each state from December 31, 2021 through January 14, 2022; this time interval corresponds to the peak of the Omicron wave. States are ordered by the highest median ratio, which is shown in red.\relax }{figure.caption.57}{}}
\newlabel{fig:unnamed-chunk-74}{{7.13}{79}{The ratio of estimated infections to observed infections for each state from December 31, 2021 through January 14, 2022; this time interval corresponds to the peak of the Omicron wave. States are ordered by the highest median ratio, which is shown in red.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.14}{\ignorespaces For each two-week interval, we rank each state's ratio of estimated to observed infections, where 1 corresponds to the state with the \emph  {lowest} ratio (indicating less infections are going unobserved), and 51 corresponds to the state with the \emph  {highest} ratio (indicating more infections are going unobserved relative to those observed). Visualized here are the states that consistently ranked as among the lowest ratios or highest ratios over time: specifically, states were among the top 10 highest ratios or top 10 lowest ratios for at least 80\% of the time intervals are shown.\relax }}{80}{figure.caption.58}\protected@file@percent }
\newlabel{fig:rank-ratio-over-time}{{7.14}{80}{For each two-week interval, we rank each state's ratio of estimated to observed infections, where 1 corresponds to the state with the \emph {lowest} ratio (indicating less infections are going unobserved), and 51 corresponds to the state with the \emph {highest} ratio (indicating more infections are going unobserved relative to those observed). Visualized here are the states that consistently ranked as among the lowest ratios or highest ratios over time: specifically, states were among the top 10 highest ratios or top 10 lowest ratios for at least 80\% of the time intervals are shown.\relax }{figure.caption.58}{}}
\newlabel{fig:unnamed-chunk-75}{{7.14}{80}{For each two-week interval, we rank each state's ratio of estimated to observed infections, where 1 corresponds to the state with the \emph {lowest} ratio (indicating less infections are going unobserved), and 51 corresponds to the state with the \emph {highest} ratio (indicating more infections are going unobserved relative to those observed). Visualized here are the states that consistently ranked as among the lowest ratios or highest ratios over time: specifically, states were among the top 10 highest ratios or top 10 lowest ratios for at least 80\% of the time intervals are shown.\relax }{figure.caption.58}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Relationship Between the Ratio of Estimated to Observed Infections Compared to Testing Rate}{81}{section.7.3}\protected@file@percent }
\newlabel{relationship-between-the-ratio-of-estimated-to-observed-infections-compared-to-testing-rate}{{7.3}{81}{Relationship Between the Ratio of Estimated to Observed Infections Compared to Testing Rate}{section.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.15}{\ignorespaces The ratio of the median estimated infections to observed infections plotted against the testing rate, where the testing rate is calculated as the total number tested in a two-week interval over the population size. When the priors are the same for all time intervals and states, there is minimal variability relationship between the testing rate and the ratio of estimated to observed infections, since the correction for incomplete testing and diagnostic test inaccuracy is identical for each time-interval and location. However, when we allow $\beta $ or $\Pr (S_1|\text  {untested})$ to vary by state and time interval, there is much variability in the relationship. A horizontal line in red at 1 is included to reference; a ratio of exactly one would indicate no infections went unobserved.\relax }}{82}{figure.caption.59}\protected@file@percent }
\newlabel{fig:testrate}{{7.15}{82}{The ratio of the median estimated infections to observed infections plotted against the testing rate, where the testing rate is calculated as the total number tested in a two-week interval over the population size. When the priors are the same for all time intervals and states, there is minimal variability relationship between the testing rate and the ratio of estimated to observed infections, since the correction for incomplete testing and diagnostic test inaccuracy is identical for each time-interval and location. However, when we allow $\beta $ or $\Pr (S_1|\text {untested})$ to vary by state and time interval, there is much variability in the relationship. A horizontal line in red at 1 is included to reference; a ratio of exactly one would indicate no infections went unobserved.\relax }{figure.caption.59}{}}
\newlabel{fig:unnamed-chunk-76}{{7.15}{82}{The ratio of the median estimated infections to observed infections plotted against the testing rate, where the testing rate is calculated as the total number tested in a two-week interval over the population size. When the priors are the same for all time intervals and states, there is minimal variability relationship between the testing rate and the ratio of estimated to observed infections, since the correction for incomplete testing and diagnostic test inaccuracy is identical for each time-interval and location. However, when we allow $\beta $ or $\Pr (S_1|\text {untested})$ to vary by state and time interval, there is much variability in the relationship. A horizontal line in red at 1 is included to reference; a ratio of exactly one would indicate no infections went unobserved.\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.16}{\ignorespaces  Comparing the biweekly testing rate by state across all 2-week intervals considered, where color is by the ratio of the student population to the census population. States are ordered by median testing rate. Data source for student population by state: the U.S. Department of Education, National Center for Education Statistics, Integrated Postsecondary Education Data System (IPEDS), 12-month Enrollment component provisional data for 2020 to 2021. Student population counts include Title IV postsecondary institutions.\relax }}{83}{figure.caption.60}\protected@file@percent }
\newlabel{fig:college}{{7.16}{83}{Comparing the biweekly testing rate by state across all 2-week intervals considered, where color is by the ratio of the student population to the census population. States are ordered by median testing rate. Data source for student population by state: the U.S. Department of Education, National Center for Education Statistics, Integrated Postsecondary Education Data System (IPEDS), 12-month Enrollment component provisional data for 2020 to 2021. Student population counts include Title IV postsecondary institutions.\relax }{figure.caption.60}{}}
\newlabel{fig:unnamed-chunk-77}{{7.16}{83}{Comparing the biweekly testing rate by state across all 2-week intervals considered, where color is by the ratio of the student population to the census population. States are ordered by median testing rate. Data source for student population by state: the U.S. Department of Education, National Center for Education Statistics, Integrated Postsecondary Education Data System (IPEDS), 12-month Enrollment component provisional data for 2020 to 2021. Student population counts include Title IV postsecondary institutions.\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}County-level Results}{84}{section.7.4}\protected@file@percent }
\newlabel{county-level-results}{{7.4}{84}{County-level Results}{section.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Massachusetts}{84}{subsection.7.4.1}\protected@file@percent }
\newlabel{massachusetts}{{7.4.1}{84}{Massachusetts}{subsection.7.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparing Implementations of Probabilistic Bias Analysis}{84}{section*.61}\protected@file@percent }
\newlabel{comparing-implementations-of-probabilistic-bias-analysis}{{7.4.1}{84}{Comparing Implementations of Probabilistic Bias Analysis}{section*.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.17}{\ignorespaces Probabilistic bias intervals for counties in Massachusetts. Each probabilistic bias interval corresponds to a 95\% simulation interval for the total number of estimated infections for that county in that two-week time interval. The columns represent different implementations of the probabilistic bias analysis. The first column corresponds to the implementation where we specify priors without using data from the COVID-19 Trends and Impact Survey. For the second column, we center the distribution of $\beta $ at the ratio of the screening test positivity to the oerall test positivity from the survey. For the third column, we center the distribution of $\Pr (S_1|\text  {untested})$ at the percentage of the population experiencing COVID-19-like illness from the survey. The fourth column centers both $\beta $ and $\Pr (S_1|\text  {untested})$ at the aforementioned values.\relax }}{86}{figure.caption.62}\protected@file@percent }
\newlabel{fig:pb_counts_ma}{{7.17}{86}{Probabilistic bias intervals for counties in Massachusetts. Each probabilistic bias interval corresponds to a 95\% simulation interval for the total number of estimated infections for that county in that two-week time interval. The columns represent different implementations of the probabilistic bias analysis. The first column corresponds to the implementation where we specify priors without using data from the COVID-19 Trends and Impact Survey. For the second column, we center the distribution of $\beta $ at the ratio of the screening test positivity to the oerall test positivity from the survey. For the third column, we center the distribution of $\Pr (S_1|\text {untested})$ at the percentage of the population experiencing COVID-19-like illness from the survey. The fourth column centers both $\beta $ and $\Pr (S_1|\text {untested})$ at the aforementioned values.\relax }{figure.caption.62}{}}
\newlabel{fig:unnamed-chunk-78}{{7.17}{86}{Probabilistic bias intervals for counties in Massachusetts. Each probabilistic bias interval corresponds to a 95\% simulation interval for the total number of estimated infections for that county in that two-week time interval. The columns represent different implementations of the probabilistic bias analysis. The first column corresponds to the implementation where we specify priors without using data from the COVID-19 Trends and Impact Survey. For the second column, we center the distribution of $\beta $ at the ratio of the screening test positivity to the oerall test positivity from the survey. For the third column, we center the distribution of $\Pr (S_1|\text {untested})$ at the percentage of the population experiencing COVID-19-like illness from the survey. The fourth column centers both $\beta $ and $\Pr (S_1|\text {untested})$ at the aforementioned values.\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.18}{\ignorespaces  Presenting the same implementations from \ref {fig:pb_counts_ma}, but not where all implementations for a county are considered in the same plot to better see the overlap between the implementations. The implementation that centers both $\Pr (S_1|\text  {untested})$ and $\beta $ at their empirical values is consistently the highest among the implementations, and the version only centering $\Pr (S_1|\text  {untested})$ at the survey value is highly concordant with the version that does not use survey data to inform the priors.\relax }}{87}{figure.caption.63}\protected@file@percent }
\newlabel{fig:pb_versions_ma}{{7.18}{87}{Presenting the same implementations from \ref {fig:pb_counts_ma}, but not where all implementations for a county are considered in the same plot to better see the overlap between the implementations. The implementation that centers both $\Pr (S_1|\text {untested})$ and $\beta $ at their empirical values is consistently the highest among the implementations, and the version only centering $\Pr (S_1|\text {untested})$ at the survey value is highly concordant with the version that does not use survey data to inform the priors.\relax }{figure.caption.63}{}}
\newlabel{fig:unnamed-chunk-79}{{7.18}{87}{Presenting the same implementations from \ref {fig:pb_counts_ma}, but not where all implementations for a county are considered in the same plot to better see the overlap between the implementations. The implementation that centers both $\Pr (S_1|\text {untested})$ and $\beta $ at their empirical values is consistently the highest among the implementations, and the version only centering $\Pr (S_1|\text {untested})$ at the survey value is highly concordant with the version that does not use survey data to inform the priors.\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.19}{\ignorespaces  To summarize the concordance with Covidestim for each county in Massachusetts, we consider the proportion of all probabilistic bias intervals (each corresponding to a two-week interval) that contain the Covidestim median for that time interval, or where the Covidestim median falls above or below the interval.\relax }}{88}{figure.caption.64}\protected@file@percent }
\newlabel{fig:summarize-concordance-mass-counties}{{7.19}{88}{To summarize the concordance with Covidestim for each county in Massachusetts, we consider the proportion of all probabilistic bias intervals (each corresponding to a two-week interval) that contain the Covidestim median for that time interval, or where the Covidestim median falls above or below the interval.\relax }{figure.caption.64}{}}
\newlabel{fig:unnamed-chunk-80}{{7.19}{88}{To summarize the concordance with Covidestim for each county in Massachusetts, we consider the proportion of all probabilistic bias intervals (each corresponding to a two-week interval) that contain the Covidestim median for that time interval, or where the Covidestim median falls above or below the interval.\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.20}{\ignorespaces  To summarize the concordance with Covidestim for each county in Massachusetts, we consider the proportion of all probabilistic bias intervals (each corresponding to a two-week interval) that contain the Covidestim median for that time interval, or where the Covidestim median falls above or below the interval. The Covidestim median falls above the probabilistic bias intervals for Suffolk and Hampshire counties in more two-week intervals than in other counties.\relax }}{89}{figure.caption.65}\protected@file@percent }
\newlabel{fig:above-below-by-county-ma}{{7.20}{89}{To summarize the concordance with Covidestim for each county in Massachusetts, we consider the proportion of all probabilistic bias intervals (each corresponding to a two-week interval) that contain the Covidestim median for that time interval, or where the Covidestim median falls above or below the interval. The Covidestim median falls above the probabilistic bias intervals for Suffolk and Hampshire counties in more two-week intervals than in other counties.\relax }{figure.caption.65}{}}
\newlabel{fig:unnamed-chunk-81}{{7.20}{89}{To summarize the concordance with Covidestim for each county in Massachusetts, we consider the proportion of all probabilistic bias intervals (each corresponding to a two-week interval) that contain the Covidestim median for that time interval, or where the Covidestim median falls above or below the interval. The Covidestim median falls above the probabilistic bias intervals for Suffolk and Hampshire counties in more two-week intervals than in other counties.\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.21}{\ignorespaces Hampshire County has among the lowest test positivity rates among counties in Massachusetts in the time period considered.\relax }}{90}{figure.caption.66}\protected@file@percent }
\newlabel{fig:hamp}{{7.21}{90}{Hampshire County has among the lowest test positivity rates among counties in Massachusetts in the time period considered.\relax }{figure.caption.66}{}}
\newlabel{fig:unnamed-chunk-82}{{7.21}{90}{Hampshire County has among the lowest test positivity rates among counties in Massachusetts in the time period considered.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparing Counties}{90}{section*.67}\protected@file@percent }
\newlabel{comparing-counties}{{7.4.1}{90}{Comparing Counties}{section*.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.22}{\ignorespaces  The ratio of estimated to observed infections across time for counties in Massachusetts. Counties are ordered by the median ratio across time intervals, from the highest ratio (Barnstable) to the lowest (Hampshire). Similar to what we saw at the state level in \ref {fig:ratio-est-observed}, the highest ratios were during the summer of 2021 during the Delta wave -- a period of decreased testing. The span of time with the highest ratio of estimated to observed infections was July 2, 2021 through July 30, 2021.\relax }}{91}{figure.caption.68}\protected@file@percent }
\newlabel{fig:ma-heatmap}{{7.22}{91}{The ratio of estimated to observed infections across time for counties in Massachusetts. Counties are ordered by the median ratio across time intervals, from the highest ratio (Barnstable) to the lowest (Hampshire). Similar to what we saw at the state level in \ref {fig:ratio-est-observed}, the highest ratios were during the summer of 2021 during the Delta wave -- a period of decreased testing. The span of time with the highest ratio of estimated to observed infections was July 2, 2021 through July 30, 2021.\relax }{figure.caption.68}{}}
\newlabel{fig:unnamed-chunk-83}{{7.22}{91}{The ratio of estimated to observed infections across time for counties in Massachusetts. Counties are ordered by the median ratio across time intervals, from the highest ratio (Barnstable) to the lowest (Hampshire). Similar to what we saw at the state level in \ref {fig:ratio-est-observed}, the highest ratios were during the summer of 2021 during the Delta wave -- a period of decreased testing. The span of time with the highest ratio of estimated to observed infections was July 2, 2021 through July 30, 2021.\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.23}{\ignorespaces The rank of the ratio of estimated infections to observed infections over time. For each two-week interval, we rank the counties by the ratio of estimated infections to observed, where a rank of 13 would indicate the county had the *highest* ratio of estimated infections to observed, and a rank of 1 would indicate the county had the *lowest* ratio of estimated infections to observed. Only counties that were consistently at the extremes, that is, that were among the highest 3 or lowest 3 for at least 80\% of the time intervals considered, are included.\relax }}{92}{figure.caption.69}\protected@file@percent }
\newlabel{fig:rank-ratio-over-time-ma-county}{{7.23}{92}{The rank of the ratio of estimated infections to observed infections over time. For each two-week interval, we rank the counties by the ratio of estimated infections to observed, where a rank of 13 would indicate the county had the *highest* ratio of estimated infections to observed, and a rank of 1 would indicate the county had the *lowest* ratio of estimated infections to observed. Only counties that were consistently at the extremes, that is, that were among the highest 3 or lowest 3 for at least 80\% of the time intervals considered, are included.\relax }{figure.caption.69}{}}
\newlabel{fig:unnamed-chunk-84}{{7.23}{92}{The rank of the ratio of estimated infections to observed infections over time. For each two-week interval, we rank the counties by the ratio of estimated infections to observed, where a rank of 13 would indicate the county had the *highest* ratio of estimated infections to observed, and a rank of 1 would indicate the county had the *lowest* ratio of estimated infections to observed. Only counties that were consistently at the extremes, that is, that were among the highest 3 or lowest 3 for at least 80\% of the time intervals considered, are included.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Michigan}{92}{subsection.7.4.2}\protected@file@percent }
\newlabel{michigan}{{7.4.2}{92}{Michigan}{subsection.7.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.24}{\ignorespaces  For each implementation, we calculate the proportion of probabilistic bias intervals over all counties and where the Covidestim median falls within, above, or below the interval. We interpret a higher proportion \emph  {in interval}, where the Covidestim falls within the probabilistic analysis interval, to indicate higher concordance. As we saw in Massachusetts (Figure \ref {fig:summarize-concordance-mass-counties}), the implementation with the highest concordance with Covidestim is the version that centers the prior for $\Pr (S_1|\text  {untested})$ at the survey value.\relax }}{93}{figure.caption.70}\protected@file@percent }
\newlabel{fig:covidestim_above_below_by_county_mi}{{7.24}{93}{For each implementation, we calculate the proportion of probabilistic bias intervals over all counties and where the Covidestim median falls within, above, or below the interval. We interpret a higher proportion \emph {in interval}, where the Covidestim falls within the probabilistic analysis interval, to indicate higher concordance. As we saw in Massachusetts (Figure \ref {fig:summarize-concordance-mass-counties}), the implementation with the highest concordance with Covidestim is the version that centers the prior for $\Pr (S_1|\text {untested})$ at the survey value.\relax }{figure.caption.70}{}}
\newlabel{fig:unnamed-chunk-85}{{7.24}{93}{For each implementation, we calculate the proportion of probabilistic bias intervals over all counties and where the Covidestim median falls within, above, or below the interval. We interpret a higher proportion \emph {in interval}, where the Covidestim falls within the probabilistic analysis interval, to indicate higher concordance. As we saw in Massachusetts (Figure \ref {fig:summarize-concordance-mass-counties}), the implementation with the highest concordance with Covidestim is the version that centers the prior for $\Pr (S_1|\text {untested})$ at the survey value.\relax }{figure.caption.70}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.25}{\ignorespaces Each row on the heatmap corresponds to a county, while each column is the two-week interval. The color of the tile for a two-week interval in a particular county is the ratio of total estimated infections to the observed infections for that two-week interval. The impelmentation of probabilistic bias analysis used for the total estimated infections is the implementation centering $\Pr (S_1|\text  {untesteed})$ at the survey value. Darker colors indicate higher ratios, where more infections were going unobserved relative to those that were observed. Intervals where the number of observed infections was zero (which is the case in some very small counties where the total number of tests, was, for instance, only 100) are shown in white, since the ratio of estimated to observed is undefined in these cases. Counties are ordered from highest to lowest by median ratio of estimated infections to observed infections. That is, counties at the top, for example, Schoolcraft and Alder, have the highest median ratios of estimated infections to observed, while counties at the bottom, for example, Washtenaw, have the lowest ratios. Across counties, we see notable increases in the summer of 2021 in June through July, and in late January through February.\relax }}{94}{figure.caption.71}\protected@file@percent }
\newlabel{fig:mi-county-heatmap}{{7.25}{94}{Each row on the heatmap corresponds to a county, while each column is the two-week interval. The color of the tile for a two-week interval in a particular county is the ratio of total estimated infections to the observed infections for that two-week interval. The impelmentation of probabilistic bias analysis used for the total estimated infections is the implementation centering $\Pr (S_1|\text {untesteed})$ at the survey value. Darker colors indicate higher ratios, where more infections were going unobserved relative to those that were observed. Intervals where the number of observed infections was zero (which is the case in some very small counties where the total number of tests, was, for instance, only 100) are shown in white, since the ratio of estimated to observed is undefined in these cases. Counties are ordered from highest to lowest by median ratio of estimated infections to observed infections. That is, counties at the top, for example, Schoolcraft and Alder, have the highest median ratios of estimated infections to observed, while counties at the bottom, for example, Washtenaw, have the lowest ratios. Across counties, we see notable increases in the summer of 2021 in June through July, and in late January through February.\relax }{figure.caption.71}{}}
\newlabel{fig:unnamed-chunk-86}{{7.25}{94}{Each row on the heatmap corresponds to a county, while each column is the two-week interval. The color of the tile for a two-week interval in a particular county is the ratio of total estimated infections to the observed infections for that two-week interval. The impelmentation of probabilistic bias analysis used for the total estimated infections is the implementation centering $\Pr (S_1|\text {untesteed})$ at the survey value. Darker colors indicate higher ratios, where more infections were going unobserved relative to those that were observed. Intervals where the number of observed infections was zero (which is the case in some very small counties where the total number of tests, was, for instance, only 100) are shown in white, since the ratio of estimated to observed is undefined in these cases. Counties are ordered from highest to lowest by median ratio of estimated infections to observed infections. That is, counties at the top, for example, Schoolcraft and Alder, have the highest median ratios of estimated infections to observed, while counties at the bottom, for example, Washtenaw, have the lowest ratios. Across counties, we see notable increases in the summer of 2021 in June through July, and in late January through February.\relax }{figure.caption.71}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.26}{\ignorespaces For each two-week interval, we rank counties by the ratio of estimated total infections to observed infections, where the highest ranking of 83 indicates the highest ratio, while the lowest possible ranking of 1 indicates the lowest ratio. Counties that fell in the top 15 or bottom 15 for at least 80\% of time intervals are included here. Lines are dotted when there is a missing value due to reporting of zero observed cases, in which case the ratio of estimated to observed infections is undefined.\relax }}{95}{figure.caption.72}\protected@file@percent }
\newlabel{fig:rank-ratio-over-time-mi-county}{{7.26}{95}{For each two-week interval, we rank counties by the ratio of estimated total infections to observed infections, where the highest ranking of 83 indicates the highest ratio, while the lowest possible ranking of 1 indicates the lowest ratio. Counties that fell in the top 15 or bottom 15 for at least 80\% of time intervals are included here. Lines are dotted when there is a missing value due to reporting of zero observed cases, in which case the ratio of estimated to observed infections is undefined.\relax }{figure.caption.72}{}}
\newlabel{fig:unnamed-chunk-87}{{7.26}{95}{For each two-week interval, we rank counties by the ratio of estimated total infections to observed infections, where the highest ranking of 83 indicates the highest ratio, while the lowest possible ranking of 1 indicates the lowest ratio. Counties that fell in the top 15 or bottom 15 for at least 80\% of time intervals are included here. Lines are dotted when there is a missing value due to reporting of zero observed cases, in which case the ratio of estimated to observed infections is undefined.\relax }{figure.caption.72}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Cross Correlation Comparison}{96}{section.7.5}\protected@file@percent }
\newlabel{cross-correlation-comparison}{{7.5}{96}{Cross Correlation Comparison}{section.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Background}{96}{subsection.7.5.1}\protected@file@percent }
\newlabel{background-1}{{7.5.1}{96}{Background}{subsection.7.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.27}{\ignorespaces In the first panel, where the time series in not differenced, the violation of second order stationarity is clear in the fact the mean is not constant over time. When we apply differencing, that is, subtracting the lagged value from each value in the series, we obtain the time series in the second panel, where the mean is constant over time. This underscores why differencing is important when interpreting the cross correlation, which assumes, in the `stats::ccf` implementation, second order stationarity.\relax }}{98}{figure.caption.73}\protected@file@percent }
\newlabel{fig:compdiff}{{7.27}{98}{In the first panel, where the time series in not differenced, the violation of second order stationarity is clear in the fact the mean is not constant over time. When we apply differencing, that is, subtracting the lagged value from each value in the series, we obtain the time series in the second panel, where the mean is constant over time. This underscores why differencing is important when interpreting the cross correlation, which assumes, in the `stats::ccf` implementation, second order stationarity.\relax }{figure.caption.73}{}}
\newlabel{fig:unnamed-chunk-88}{{7.27}{98}{In the first panel, where the time series in not differenced, the violation of second order stationarity is clear in the fact the mean is not constant over time. When we apply differencing, that is, subtracting the lagged value from each value in the series, we obtain the time series in the second panel, where the mean is constant over time. This underscores why differencing is important when interpreting the cross correlation, which assumes, in the `stats::ccf` implementation, second order stationarity.\relax }{figure.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.28}{\ignorespaces In the first panel, we consider the time series that has not been differenced, and see that the lag at which the maximum cross correlation occurs is not the true lag. When we apply differencing, we see in the second panel that the maximum correlation occurs at the true lag.\relax }}{99}{figure.caption.74}\protected@file@percent }
\newlabel{fig:corzy}{{7.28}{99}{In the first panel, we consider the time series that has not been differenced, and see that the lag at which the maximum cross correlation occurs is not the true lag. When we apply differencing, we see in the second panel that the maximum correlation occurs at the true lag.\relax }{figure.caption.74}{}}
\newlabel{fig:unnamed-chunk-89}{{7.28}{99}{In the first panel, we consider the time series that has not been differenced, and see that the lag at which the maximum cross correlation occurs is not the true lag. When we apply differencing, we see in the second panel that the maximum correlation occurs at the true lag.\relax }{figure.caption.74}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Cross Correlation Results Comparing Bias-Corrected Counts, Covidestim Estimates, and Wastewater Concentrations}{99}{subsection.7.5.2}\protected@file@percent }
\newlabel{cross-correlation-results-comparing-bias-corrected-counts-covidestim-estimates-and-wastewater-concentrations}{{7.5.2}{99}{Cross Correlation Results Comparing Bias-Corrected Counts, Covidestim Estimates, and Wastewater Concentrations}{subsection.7.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.29}{\ignorespaces \relax }}{100}{figure.caption.75}\protected@file@percent }
\newlabel{fig:wastewater_ma_by_county}{{7.29}{100}{\relax }{figure.caption.75}{}}
\newlabel{fig:unnamed-chunk-90}{{7.29}{100}{\relax }{figure.caption.75}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison Between Implementations of Probabilistic Bias Analysis}{101}{section*.76}\protected@file@percent }
\newlabel{comparison-between-implementations-of-probabilistic-bias-analysis}{{7.5.2}{101}{Comparison Between Implementations of Probabilistic Bias Analysis}{section*.76}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.30}{\ignorespaces For each implementation of the priors, we consider the maximum cross correlation between the estimated infections for the two week interval and the mean effective concentration of SARS-CoV-2 in the wastewater for that two-week interval. We also include the cross correlation between the observed infections and effective wastewater concentration to see how the correlations between the bias-corrected estimates with wastewater concentrations compare to the correlations between the observed infections and wastewater concentrations. The shape of the point (circle, square, or triangle) indicates the lag at which the maximum correlation was obtained. For instance, a lag of -1 would indicate the maximum correlation between the time series and wastewater concentrations is when wastewater concentrations lead infections by one two-week interval. In most cases, the lag was zero.\relax }}{102}{figure.caption.77}\protected@file@percent }
\newlabel{fig:correlation_observed_pb}{{7.30}{102}{For each implementation of the priors, we consider the maximum cross correlation between the estimated infections for the two week interval and the mean effective concentration of SARS-CoV-2 in the wastewater for that two-week interval. We also include the cross correlation between the observed infections and effective wastewater concentration to see how the correlations between the bias-corrected estimates with wastewater concentrations compare to the correlations between the observed infections and wastewater concentrations. The shape of the point (circle, square, or triangle) indicates the lag at which the maximum correlation was obtained. For instance, a lag of -1 would indicate the maximum correlation between the time series and wastewater concentrations is when wastewater concentrations lead infections by one two-week interval. In most cases, the lag was zero.\relax }{figure.caption.77}{}}
\newlabel{fig:unnamed-chunk-91}{{7.30}{102}{For each implementation of the priors, we consider the maximum cross correlation between the estimated infections for the two week interval and the mean effective concentration of SARS-CoV-2 in the wastewater for that two-week interval. We also include the cross correlation between the observed infections and effective wastewater concentration to see how the correlations between the bias-corrected estimates with wastewater concentrations compare to the correlations between the observed infections and wastewater concentrations. The shape of the point (circle, square, or triangle) indicates the lag at which the maximum correlation was obtained. For instance, a lag of -1 would indicate the maximum correlation between the time series and wastewater concentrations is when wastewater concentrations lead infections by one two-week interval. In most cases, the lag was zero.\relax }{figure.caption.77}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison Between Covidestim, Observed Cases, and Bias-Corrected Counts}{102}{section*.78}\protected@file@percent }
\newlabel{comparison-between-covidestim-observed-cases-and-bias-corrected-counts}{{7.5.2}{102}{Comparison Between Covidestim, Observed Cases, and Bias-Corrected Counts}{section*.78}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.31}{\ignorespaces \relax }}{103}{figure.caption.79}\protected@file@percent }
\newlabel{fig:correlation_observed_pb_covidestim}{{7.31}{103}{\relax }{figure.caption.79}{}}
\newlabel{fig:unnamed-chunk-92}{{7.31}{103}{\relax }{figure.caption.79}{}}
\@writefile{toc}{\contentsline {subsubsection}{Takeaways}{103}{section*.80}\protected@file@percent }
\newlabel{takeaways}{{7.5.2}{103}{Takeaways}{section*.80}{}}
\@writefile{toc}{\contentsline {chapter}{Chapter 8: Conclusion}{105}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusion}{{8}{105}{Conclusion}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Limitations and Future Work}{105}{section.8.1}\protected@file@percent }
\newlabel{limitations-and-future-work}{{8.1}{105}{Limitations and Future Work}{section.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Population Estimates}{105}{subsection.8.1.1}\protected@file@percent }
\newlabel{population-estimates}{{8.1.1}{105}{Population Estimates}{subsection.8.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Correlation Between \(\alpha \) and \(\beta \)}{105}{subsection.8.1.2}\protected@file@percent }
\newlabel{correlation-between-alpha-and-beta}{{8.1.2}{105}{\texorpdfstring {Correlation Between \(\alpha \) and \(\beta \)}{Correlation Between \textbackslash alpha and \textbackslash beta}}{subsection.8.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Using Results for Other Sensitivity Analyses}{106}{subsection.8.1.3}\protected@file@percent }
\newlabel{using-results-for-other-sensitivity-analyses}{{8.1.3}{106}{Using Results for Other Sensitivity Analyses}{subsection.8.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Discussion}{106}{section.8.2}\protected@file@percent }
\newlabel{discussion}{{8.2}{106}{Discussion}{section.8.2}{}}
\@writefile{toc}{\contentsline {chapter}{Appendix A: Appendix}{109}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{109}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}LOESS Smoothing}{109}{section.A.1}\protected@file@percent }
\newlabel{loess}{{A.1}{109}{LOESS Smoothing}{section.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Fitting the LOESS Curve}{109}{subsection.A.1.1}\protected@file@percent }
\newlabel{fitting-the-loess-curve}{{A.1.1}{109}{Fitting the LOESS Curve}{subsection.A.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces  The only values with nonzero weights are those within the interval $(500 - \alpha (n), 500 - \alpha (n))$. That is, the proportion $\alpha $ of the data points closest to $x^*$ will have nonzero weights.\relax }}{110}{figure.caption.81}\protected@file@percent }
\newlabel{fig:weights}{{A.1}{110}{The only values with nonzero weights are those within the interval $(500 - \alpha (n), 500 - \alpha (n))$. That is, the proportion $\alpha $ of the data points closest to $x^*$ will have nonzero weights.\relax }{figure.caption.81}{}}
\newlabel{fig:unnamed-chunk-95}{{A.1}{110}{The only values with nonzero weights are those within the interval $(500 - \alpha (n), 500 - \alpha (n))$. That is, the proportion $\alpha $ of the data points closest to $x^*$ will have nonzero weights.\relax }{figure.caption.81}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces \relax }}{110}{figure.caption.82}\protected@file@percent }
\newlabel{fig:ex-poly}{{A.2}{110}{\relax }{figure.caption.82}{}}
\newlabel{fig:unnamed-chunk-96}{{A.2}{110}{\relax }{figure.caption.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces \relax }}{111}{figure.caption.83}\protected@file@percent }
\newlabel{fig:loess-all}{{A.3}{111}{\relax }{figure.caption.83}{}}
\newlabel{fig:unnamed-chunk-98}{{A.3}{111}{\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Transformation Approach to Bounded Density Estimation}{111}{section.A.2}\protected@file@percent }
\newlabel{bounded-density-transform}{{A.2}{111}{Transformation Approach to Bounded Density Estimation}{section.A.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces \relax }}{112}{figure.caption.85}\protected@file@percent }
\newlabel{fig:trans}{{A.4}{112}{\relax }{figure.caption.85}{}}
\newlabel{fig:unnamed-chunk-102}{{A.4}{112}{\relax }{figure.caption.85}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces \relax }}{113}{figure.caption.86}\protected@file@percent }
\newlabel{fig:original}{{A.5}{113}{\relax }{figure.caption.86}{}}
\newlabel{fig:create-fig-original}{{A.5}{113}{\relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces \relax }}{114}{figure.caption.87}\protected@file@percent }
\newlabel{fig:compare-beta-params}{{A.6}{114}{\relax }{figure.caption.87}{}}
\newlabel{fig:unnamed-chunk-104}{{A.6}{114}{\relax }{figure.caption.87}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Beta Kernel Density Estimation}{115}{section.A.3}\protected@file@percent }
\newlabel{betakernel}{{A.3}{115}{Beta Kernel Density Estimation}{section.A.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.7}{\ignorespaces \relax }}{115}{figure.caption.88}\protected@file@percent }
\newlabel{fig:depends-on-x}{{A.7}{115}{\relax }{figure.caption.88}{}}
\newlabel{fig:unnamed-chunk-106}{{A.7}{115}{\relax }{figure.caption.88}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.8}{\ignorespaces \relax }}{116}{figure.caption.89}\protected@file@percent }
\newlabel{fig:comp-beta}{{A.8}{116}{\relax }{figure.caption.89}{}}
\newlabel{fig:unnamed-chunk-108}{{A.8}{116}{\relax }{figure.caption.89}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Total Tests and Positive Tests Across All States}{117}{section.A.4}\protected@file@percent }
\newlabel{total-tests-and-positive-tests-across-all-states}{{A.4}{117}{Total Tests and Positive Tests Across All States}{section.A.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.9}{\ignorespaces  Percent change in positive tests and the percent change in total tests from March 2021 through the end of February 2022. We see in the period from July through September that the positive tests consistently increase at a higher rate than the total tests; this is related to the peaks we observe in the probabilistic bias intervals.\relax }}{117}{figure.caption.90}\protected@file@percent }
\newlabel{fig:test-capacity-all-states}{{A.9}{117}{Percent change in positive tests and the percent change in total tests from March 2021 through the end of February 2022. We see in the period from July through September that the positive tests consistently increase at a higher rate than the total tests; this is related to the peaks we observe in the probabilistic bias intervals.\relax }{figure.caption.90}{}}
\newlabel{fig:unnamed-chunk-109}{{A.9}{117}{Percent change in positive tests and the percent change in total tests from March 2021 through the end of February 2022. We see in the period from July through September that the positive tests consistently increase at a higher rate than the total tests; this is related to the peaks we observe in the probabilistic bias intervals.\relax }{figure.caption.90}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.5}Comparing Johns Hopkins CSSE Cases to CDC Positive Tests}{119}{section.A.5}\protected@file@percent }
\newlabel{comparing-johns-hopkins-csse-cases-to-cdc-positive-tests}{{A.5}{119}{Comparing Johns Hopkins CSSE Cases to CDC Positive Tests}{section.A.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.10}{\ignorespaces Comparing the data sources for the probablistic bias analysis and the Covidestim model. The two solid lines are the data sources: the data source for the probabilistic analysis is PCR tests from the CDC's Diagnostic Laboratory Testing Time series, while the data source for the Covidestim model is Johns Hopkins CSSE case counts. Each is summed across 2-week intervals time scale. The test positivity is the positive tests from the CDC source over total tests for the two-week interval. Looking at trends in the test positivity are informative for better understanding when Covidestim estimates lag the probabilistic bias intervals. This figure contains half of the states; the next half are in the following figure.\relax }}{119}{figure.caption.91}\protected@file@percent }
\newlabel{fig:jhu-cdc-all}{{A.10}{119}{Comparing the data sources for the probablistic bias analysis and the Covidestim model. The two solid lines are the data sources: the data source for the probabilistic analysis is PCR tests from the CDC's Diagnostic Laboratory Testing Time series, while the data source for the Covidestim model is Johns Hopkins CSSE case counts. Each is summed across 2-week intervals time scale. The test positivity is the positive tests from the CDC source over total tests for the two-week interval. Looking at trends in the test positivity are informative for better understanding when Covidestim estimates lag the probabilistic bias intervals. This figure contains half of the states; the next half are in the following figure.\relax }{figure.caption.91}{}}
\newlabel{fig:unnamed-chunk-110}{{A.10}{119}{Comparing the data sources for the probablistic bias analysis and the Covidestim model. The two solid lines are the data sources: the data source for the probabilistic analysis is PCR tests from the CDC's Diagnostic Laboratory Testing Time series, while the data source for the Covidestim model is Johns Hopkins CSSE case counts. Each is summed across 2-week intervals time scale. The test positivity is the positive tests from the CDC source over total tests for the two-week interval. Looking at trends in the test positivity are informative for better understanding when Covidestim estimates lag the probabilistic bias intervals. This figure contains half of the states; the next half are in the following figure.\relax }{figure.caption.91}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.11}{\ignorespaces  This figure provides the same information as \ref {fig:jhu-cdc-all} for the second half of the states.\relax }}{120}{figure.caption.92}\protected@file@percent }
\newlabel{fig:jhu-cdc-all2}{{A.11}{120}{This figure provides the same information as \ref {fig:jhu-cdc-all} for the second half of the states.\relax }{figure.caption.92}{}}
\newlabel{fig:unnamed-chunk-111}{{A.11}{120}{This figure provides the same information as \ref {fig:jhu-cdc-all} for the second half of the states.\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.6}First Implementation of Probabilistic Bias Analysis (Including All States)}{121}{section.A.6}\protected@file@percent }
\newlabel{first-implementation-of-probabilistic-bias-analysis-including-all-states}{{A.6}{121}{First Implementation of Probabilistic Bias Analysis (Including All States)}{section.A.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.12}{\ignorespaces  Probabilistic bias analysis 95\% simulation intervals for each two-week interval and state for the implementation where priors do not vary by location or time-interval.\relax }}{122}{figure.caption.93}\protected@file@percent }
\newlabel{fig:all-states-first-impl}{{A.12}{122}{Probabilistic bias analysis 95\% simulation intervals for each two-week interval and state for the implementation where priors do not vary by location or time-interval.\relax }{figure.caption.93}{}}
\newlabel{fig:unnamed-chunk-112}{{A.12}{122}{Probabilistic bias analysis 95\% simulation intervals for each two-week interval and state for the implementation where priors do not vary by location or time-interval.\relax }{figure.caption.93}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.7}County Level Comparison to Covidestim in Massachusetts}{123}{section.A.7}\protected@file@percent }
\newlabel{county-level-comparison-to-covidestim-in-massachusetts}{{A.7}{123}{County Level Comparison to Covidestim in Massachusetts}{section.A.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.13}{\ignorespaces Probabilistic bias analysis intervals for each county in Massachusetts. Each probabilistic bias interval is a 95\% simulation interval for the estimated infections in that particular two-week interval. Each column represents a distinct implementation of the probabilistic bias analysis, where columns 2 through 4 incorporate survey data from the COVID-19 Trends and Impact Survey for informing the prior distributions. The Covidestim medians are presented in blue to compare concordance between each implementation of the bias analysis to Covidestim estimates.\relax }}{123}{figure.caption.94}\protected@file@percent }
\newlabel{fig:ma-comp-covidestim}{{A.13}{123}{Probabilistic bias analysis intervals for each county in Massachusetts. Each probabilistic bias interval is a 95\% simulation interval for the estimated infections in that particular two-week interval. Each column represents a distinct implementation of the probabilistic bias analysis, where columns 2 through 4 incorporate survey data from the COVID-19 Trends and Impact Survey for informing the prior distributions. The Covidestim medians are presented in blue to compare concordance between each implementation of the bias analysis to Covidestim estimates.\relax }{figure.caption.94}{}}
\newlabel{fig:unnamed-chunk-113}{{A.13}{123}{Probabilistic bias analysis intervals for each county in Massachusetts. Each probabilistic bias interval is a 95\% simulation interval for the estimated infections in that particular two-week interval. Each column represents a distinct implementation of the probabilistic bias analysis, where columns 2 through 4 incorporate survey data from the COVID-19 Trends and Impact Survey for informing the prior distributions. The Covidestim medians are presented in blue to compare concordance between each implementation of the bias analysis to Covidestim estimates.\relax }{figure.caption.94}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.8}Full Set of Results at the County Level for Michigan}{125}{section.A.8}\protected@file@percent }
\newlabel{full-set-of-results-at-the-county-level-for-michigan}{{A.8}{125}{Full Set of Results at the County Level for Michigan}{section.A.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.14}{\ignorespaces  Probabilistic bias intervals for each implementation of probabilistic bias analysis, for each county in Michigan. Each interval is a 95\% simulation interval for the total number of infections in that county in that two-week interval. The counties in Michigan are divided into thirds; this figure shows the first third, and the following two figures show the remaining counties.\relax }}{125}{figure.caption.95}\protected@file@percent }
\newlabel{fig:pb_versions_mi-1}{{A.14}{125}{Probabilistic bias intervals for each implementation of probabilistic bias analysis, for each county in Michigan. Each interval is a 95\% simulation interval for the total number of infections in that county in that two-week interval. The counties in Michigan are divided into thirds; this figure shows the first third, and the following two figures show the remaining counties.\relax }{figure.caption.95}{}}
\newlabel{fig:unnamed-chunk-114}{{A.14}{125}{Probabilistic bias intervals for each implementation of probabilistic bias analysis, for each county in Michigan. Each interval is a 95\% simulation interval for the total number of infections in that county in that two-week interval. The counties in Michigan are divided into thirds; this figure shows the first third, and the following two figures show the remaining counties.\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.15}{\ignorespaces  This figure is identical to \ref {fig:pb_versions_mi-1} but shows the second third of counties in Michigan.\relax }}{126}{figure.caption.96}\protected@file@percent }
\newlabel{fig:pb_versions_mi-2}{{A.15}{126}{This figure is identical to \ref {fig:pb_versions_mi-1} but shows the second third of counties in Michigan.\relax }{figure.caption.96}{}}
\newlabel{fig:unnamed-chunk-115}{{A.15}{126}{This figure is identical to \ref {fig:pb_versions_mi-1} but shows the second third of counties in Michigan.\relax }{figure.caption.96}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.16}{\ignorespaces  This figure is identical to \ref {fig:pb_versions_mi-1} but shows the last third of counties in Michigan.\relax }}{127}{figure.caption.97}\protected@file@percent }
\newlabel{fig:pb_versions_mi-3}{{A.16}{127}{This figure is identical to \ref {fig:pb_versions_mi-1} but shows the last third of counties in Michigan.\relax }{figure.caption.97}{}}
\newlabel{fig:unnamed-chunk-116}{{A.16}{127}{This figure is identical to \ref {fig:pb_versions_mi-1} but shows the last third of counties in Michigan.\relax }{figure.caption.97}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.9}Concordance with Covidestim by Version and County in Michigan}{128}{section.A.9}\protected@file@percent }
\newlabel{concordance-with-covidestim-by-version-and-county-in-michigan}{{A.9}{128}{Concordance with Covidestim by Version and County in Michigan}{section.A.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.17}{\ignorespaces  Considering the proportion of probabilistic bias intervals that contained the Covidestim median for each implementation, for each county in Michigan. For most counties, we see that the implementation centering $P(S_1|\text  {untested})$ at the survey value is most concordant with Covidestim.\relax }}{128}{figure.caption.98}\protected@file@percent }
\newlabel{fig:mi-county-concordance}{{A.17}{128}{Considering the proportion of probabilistic bias intervals that contained the Covidestim median for each implementation, for each county in Michigan. For most counties, we see that the implementation centering $P(S_1|\text {untested})$ at the survey value is most concordant with Covidestim.\relax }{figure.caption.98}{}}
\newlabel{fig:unnamed-chunk-117}{{A.17}{128}{Considering the proportion of probabilistic bias intervals that contained the Covidestim median for each implementation, for each county in Michigan. For most counties, we see that the implementation centering $P(S_1|\text {untested})$ at the survey value is most concordant with Covidestim.\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.10}Ratio of Estimated Infections to Observed in Michigan Counties, by Population Size}{129}{section.A.10}\protected@file@percent }
\newlabel{ratio-of-estimated-infections-to-observed-in-michigan-counties-by-population-size}{{A.10}{129}{Ratio of Estimated Infections to Observed in Michigan Counties, by Population Size}{section.A.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.18}{\ignorespaces Comparing the ratio of estimated infections to observed infections over time for counties of different population sizes in Michigan. Counties are split into four groups based on quartiles of the population size. Each point represents the ratio of the estimated infections to the observed infections for a county. Although the group with the smallest population size does have more outliers with very high ratios, the median ratios are highly similar across population sizes.\relax }}{129}{figure.caption.99}\protected@file@percent }
\newlabel{fig:mi-ratio-pop}{{A.18}{129}{Comparing the ratio of estimated infections to observed infections over time for counties of different population sizes in Michigan. Counties are split into four groups based on quartiles of the population size. Each point represents the ratio of the estimated infections to the observed infections for a county. Although the group with the smallest population size does have more outliers with very high ratios, the median ratios are highly similar across population sizes.\relax }{figure.caption.99}{}}
\newlabel{fig:unnamed-chunk-118}{{A.18}{129}{Comparing the ratio of estimated infections to observed infections over time for counties of different population sizes in Michigan. Counties are split into four groups based on quartiles of the population size. Each point represents the ratio of the estimated infections to the observed infections for a county. Although the group with the smallest population size does have more outliers with very high ratios, the median ratios are highly similar across population sizes.\relax }{figure.caption.99}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.11}Lack of Change in \(\alpha \) with Melding}{130}{section.A.11}\protected@file@percent }
\newlabel{alpha-melding}{{A.11}{130}{\texorpdfstring {Lack of Change in \(\alpha \) with Melding}{Lack of Change in \textbackslash alpha with Melding}}{section.A.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.19}{\ignorespaces Holding $\Pr (S_1|\text  {untested})$ constant and considering $\alpha \in (0.7,1.3)$ and $\beta \in (0.01,0.4)$, where these ranges contain all values where the prior distribution has nontrivial density, we see that $M(\theta )$ is much more sensitive to changes in $\beta $ than to changes in $\alpha $. A consequence of this is the lack of change we see in $\alpha $ in the post-melding distributions.\relax }}{130}{figure.caption.100}\protected@file@percent }
\newlabel{fig:alpha-little-change}{{A.19}{130}{Holding $\Pr (S_1|\text {untested})$ constant and considering $\alpha \in (0.7,1.3)$ and $\beta \in (0.01,0.4)$, where these ranges contain all values where the prior distribution has nontrivial density, we see that $M(\theta )$ is much more sensitive to changes in $\beta $ than to changes in $\alpha $. A consequence of this is the lack of change we see in $\alpha $ in the post-melding distributions.\relax }{figure.caption.100}{}}
\newlabel{fig:unnamed-chunk-119}{{A.19}{130}{Holding $\Pr (S_1|\text {untested})$ constant and considering $\alpha \in (0.7,1.3)$ and $\beta \in (0.01,0.4)$, where these ranges contain all values where the prior distribution has nontrivial density, we see that $M(\theta )$ is much more sensitive to changes in $\beta $ than to changes in $\alpha $. A consequence of this is the lack of change we see in $\alpha $ in the post-melding distributions.\relax }{figure.caption.100}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.12}Relationship Between \((X+Y)_\alpha \) and \(X_{\alpha }\) +\(Y_{\alpha }\) for Dependent Variables}{131}{section.A.12}\protected@file@percent }
\newlabel{conservativeintervals}{{A.12}{131}{\texorpdfstring {Relationship Between \((X+Y)_\alpha \) and \(X_{\alpha }\) +\(Y_{\alpha }\) for Dependent Variables}{Relationship Between (X+Y)\_\textbackslash alpha and X\_\{\textbackslash alpha\} +Y\_\{\textbackslash alpha\} for Dependent Variables}}{section.A.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.12.1}Simulation: Bivariate Normal}{131}{subsection.A.12.1}\protected@file@percent }
\newlabel{simulation-bivariate-normal}{{A.12.1}{131}{Simulation: Bivariate Normal}{subsection.A.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.20}{\ignorespaces \relax }}{132}{figure.caption.101}\protected@file@percent }
\newlabel{fig:simmvn}{{A.20}{132}{\relax }{figure.caption.101}{}}
\newlabel{fig:unnamed-chunk-120}{{A.20}{132}{\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.21}{\ignorespaces \relax }}{133}{figure.caption.102}\protected@file@percent }
\newlabel{fig:comp-intervals}{{A.21}{133}{\relax }{figure.caption.102}{}}
\newlabel{fig:unnamed-chunk-121}{{A.21}{133}{\relax }{figure.caption.102}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.12.2}Derivation of the Distribution of X+Y for Bivariate Normal}{134}{subsection.A.12.2}\protected@file@percent }
\newlabel{derivation-of-the-distribution-of-xy-for-bivariate-normal}{{A.12.2}{134}{Derivation of the Distribution of X+Y for Bivariate Normal}{subsection.A.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.22}{\ignorespaces  The theoretical density of $N\left (\bar  x + \bar  y,\sqrt  {\sigma _x^2 +\sigma _y^2 + 2 \rho \sigma _x \sigma _y }\right )$ is plotted in red over the kernel density estimate of the observed distribution of $X+Y$.\relax }}{135}{figure.caption.103}\protected@file@percent }
\newlabel{fig:ex-sim-normal}{{A.22}{135}{The theoretical density of $N\left (\bar x + \bar y,\sqrt {\sigma _x^2 +\sigma _y^2 + 2 \rho \sigma _x \sigma _y }\right )$ is plotted in red over the kernel density estimate of the observed distribution of $X+Y$.\relax }{figure.caption.103}{}}
\newlabel{fig:unnamed-chunk-124}{{A.22}{135}{The theoretical density of $N\left (\bar x + \bar y,\sqrt {\sigma _x^2 +\sigma _y^2 + 2 \rho \sigma _x \sigma _y }\right )$ is plotted in red over the kernel density estimate of the observed distribution of $X+Y$.\relax }{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.23}{\ignorespaces \relax }}{136}{figure.caption.104}\protected@file@percent }
\newlabel{fig:erf}{{A.23}{136}{\relax }{figure.caption.104}{}}
\newlabel{fig:unnamed-chunk-125}{{A.23}{136}{\relax }{figure.caption.104}{}}
\newlabel{references}{{A.12.2}{137}{References}{appendix*.105}{}}
\@writefile{toc}{\contentsline {chapter}{References}{137}{appendix*.105}\protected@file@percent }
\gdef \@abspage@last{154}
